{"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import tensorflow as tf\n","import random as rn\n","import pickle\n","\n","import os\n","\n","os.environ['PYTHONHASHSEED'] = str(42)\n","\n","os.environ['TF_DETERMINISTIC_OPS'] = '1'\n","os.environ['TF_CUDNN_DETERMINISTIC'] = '1'\n","\n","tf.random.set_seed(42)\n","np.random.seed(42)\n","rn.seed(42)"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["train_dir = './data/X_train.pickle'\n","train_label_dir = './data/data_y_train.csv'\n","test_dir = './data/X_test.pickle'\n","test_label_dir = './data/data_y_test.csv'\n","\n","with open(train_dir,'rb') as frb:\n","    X_train = pickle.load(frb) # train_feature_load\n","\n","with open(test_dir,'rb') as frb:\n","    X_test = pickle.load(frb) # train_feature_load\n","\n","X_train = np.array(X_train)[:,:,2:]\n","X_test = np.array(X_test)[:,:,2:]\n","y_train = pd.read_csv(train_label_dir)['label']  # train_label load\n","y_test = pd.read_csv(test_label_dir)['label']  # train_label load"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["from tensorflow.keras import layers, initializers\n","from tensorflow.keras.models import Model"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_1 (InputLayer)         [(None, 600, 8)]          0         \n_________________________________________________________________\nconv1d (Conv1D)              (None, 300, 128)          19584     \n_________________________________________________________________\nbatch_normalization (BatchNo (None, 300, 128)          512       \n_________________________________________________________________\ndropout (Dropout)            (None, 300, 128)          0         \n_________________________________________________________________\nconv1d_1 (Conv1D)            (None, 150, 256)          622848    \n_________________________________________________________________\nbatch_normalization_1 (Batch (None, 150, 256)          1024      \n_________________________________________________________________\ndropout_1 (Dropout)          (None, 150, 256)          0         \n_________________________________________________________________\nconv1d_2 (Conv1D)            (None, 75, 128)           1409152   \n_________________________________________________________________\nbatch_normalization_2 (Batch (None, 75, 128)           512       \n_________________________________________________________________\ndropout_2 (Dropout)          (None, 75, 128)           0         \n_________________________________________________________________\nglobal_average_pooling1d (Gl (None, 128)               0         \n_________________________________________________________________\nbatch_normalization_3 (Batch (None, 128)               512       \n_________________________________________________________________\ndense (Dense)                (None, 61)                7869      \n=================================================================\nTotal params: 2,062,013\nTrainable params: 2,060,733\nNon-trainable params: 1,280\n_________________________________________________________________\n"]}],"source":["filter_1 = 19\n","filter_2 = 19\n","filter_3 = 43\n","channel_1 = 128\n","channel_2 = 256\n","channel_3 = 128\n","input_channel = 8\n","stride = 2\n","drop_rate = 0.3\n","\n","inputs = layers.Input(shape=(600,input_channel))\n","\n","conv = layers.Conv1D(\n","    channel_1,filter_1,strides=stride,padding='same',activation='relu',\n","    kernel_initializer=initializers.he_normal(seed=42))(inputs)\n","conv = layers.BatchNormalization()(conv)\n","conv = layers.Dropout(drop_rate,seed=42)(conv)\n","\n","conv = layers.Conv1D(\n","    channel_2,filter_2,strides=stride,padding='same',activation='relu',\n","    kernel_initializer=initializers.he_normal(seed=42))(conv)\n","conv = layers.BatchNormalization()(conv)\n","conv = layers.Dropout(drop_rate,seed=42)(conv)\n","\n","conv = layers.Conv1D(\n","    channel_3,filter_3,strides=stride,padding='same',activation='relu',\n","    kernel_initializer=initializers.he_normal(seed=42))(conv)\n","conv = layers.BatchNormalization()(conv)\n","conv = layers.Dropout(drop_rate,seed=42)(conv)\n","\n","pool = layers.GlobalAveragePooling1D()(conv)\n","pool = layers.BatchNormalization()(pool)\n","\n","outputs = layers.Dense(61,activation='softmax',kernel_initializer=initializers.he_normal(seed=42))(pool)\n","model = Model(inputs,outputs)\n","\n","model.compile(optimizer='adam', loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n","\n","model.summary()"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/2000\n","63/63 [==============================] - 4s 21ms/step - loss: 2.7584 - accuracy: 0.4560 - val_loss: 2.5592 - val_accuracy: 0.5020\n","\n","Epoch 00001: val_loss improved from inf to 2.55925, saving model to ./save/simple_cnn_best.hdf5\n","Epoch 2/2000\n","63/63 [==============================] - 1s 16ms/step - loss: 1.9199 - accuracy: 0.5735 - val_loss: 2.7983 - val_accuracy: 0.5200\n","\n","Epoch 00002: val_loss did not improve from 2.55925\n","Epoch 3/2000\n","63/63 [==============================] - 1s 16ms/step - loss: 1.4781 - accuracy: 0.6265 - val_loss: 3.1699 - val_accuracy: 0.5000\n","\n","Epoch 00003: val_loss did not improve from 2.55925\n","Epoch 4/2000\n","63/63 [==============================] - 1s 16ms/step - loss: 1.2330 - accuracy: 0.6820 - val_loss: 3.3224 - val_accuracy: 0.5020\n","\n","Epoch 00004: val_loss did not improve from 2.55925\n","Epoch 5/2000\n","63/63 [==============================] - 1s 16ms/step - loss: 1.0431 - accuracy: 0.7220 - val_loss: 3.7095 - val_accuracy: 0.4840\n","\n","Epoch 00005: val_loss did not improve from 2.55925\n","Epoch 6/2000\n","63/63 [==============================] - 1s 16ms/step - loss: 0.9139 - accuracy: 0.7435 - val_loss: 4.5535 - val_accuracy: 0.0220\n","\n","Epoch 00006: val_loss did not improve from 2.55925\n","\n","Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","Epoch 7/2000\n","63/63 [==============================] - 1s 16ms/step - loss: 0.7277 - accuracy: 0.7940 - val_loss: 3.5665 - val_accuracy: 0.0540\n","\n","Epoch 00007: val_loss did not improve from 2.55925\n","Epoch 8/2000\n","63/63 [==============================] - 1s 16ms/step - loss: 0.6546 - accuracy: 0.8110 - val_loss: 2.4200 - val_accuracy: 0.4400\n","\n","Epoch 00008: val_loss improved from 2.55925 to 2.41999, saving model to ./save/simple_cnn_best.hdf5\n","Epoch 9/2000\n","63/63 [==============================] - 1s 16ms/step - loss: 0.6218 - accuracy: 0.8145 - val_loss: 1.8444 - val_accuracy: 0.5000\n","\n","Epoch 00009: val_loss improved from 2.41999 to 1.84439, saving model to ./save/simple_cnn_best.hdf5\n","Epoch 10/2000\n","63/63 [==============================] - 1s 16ms/step - loss: 0.5960 - accuracy: 0.8325 - val_loss: 1.2274 - val_accuracy: 0.6860\n","\n","Epoch 00010: val_loss improved from 1.84439 to 1.22737, saving model to ./save/simple_cnn_best.hdf5\n","Epoch 11/2000\n","63/63 [==============================] - 1s 16ms/step - loss: 0.5217 - accuracy: 0.8495 - val_loss: 0.9807 - val_accuracy: 0.7300\n","\n","Epoch 00011: val_loss improved from 1.22737 to 0.98066, saving model to ./save/simple_cnn_best.hdf5\n","Epoch 12/2000\n","63/63 [==============================] - 1s 16ms/step - loss: 0.4944 - accuracy: 0.8500 - val_loss: 0.7648 - val_accuracy: 0.7620\n","\n","Epoch 00012: val_loss improved from 0.98066 to 0.76480, saving model to ./save/simple_cnn_best.hdf5\n","Epoch 13/2000\n","63/63 [==============================] - 1s 16ms/step - loss: 0.4642 - accuracy: 0.8595 - val_loss: 0.7316 - val_accuracy: 0.7720\n","\n","Epoch 00013: val_loss improved from 0.76480 to 0.73156, saving model to ./save/simple_cnn_best.hdf5\n","Epoch 14/2000\n","63/63 [==============================] - 1s 16ms/step - loss: 0.4313 - accuracy: 0.8660 - val_loss: 0.6958 - val_accuracy: 0.7740\n","\n","Epoch 00014: val_loss improved from 0.73156 to 0.69583, saving model to ./save/simple_cnn_best.hdf5\n","Epoch 15/2000\n","63/63 [==============================] - 1s 16ms/step - loss: 0.4045 - accuracy: 0.8750 - val_loss: 0.6710 - val_accuracy: 0.7960\n","\n","Epoch 00015: val_loss improved from 0.69583 to 0.67096, saving model to ./save/simple_cnn_best.hdf5\n","Epoch 16/2000\n","63/63 [==============================] - 1s 16ms/step - loss: 0.3810 - accuracy: 0.8780 - val_loss: 0.7124 - val_accuracy: 0.8040\n","\n","Epoch 00016: val_loss did not improve from 0.67096\n","Epoch 17/2000\n","63/63 [==============================] - 1s 16ms/step - loss: 0.3774 - accuracy: 0.8840 - val_loss: 0.6356 - val_accuracy: 0.8140\n","\n","Epoch 00017: val_loss improved from 0.67096 to 0.63563, saving model to ./save/simple_cnn_best.hdf5\n","Epoch 18/2000\n","63/63 [==============================] - 1s 16ms/step - loss: 0.3305 - accuracy: 0.9000 - val_loss: 0.7285 - val_accuracy: 0.7760\n","\n","Epoch 00018: val_loss did not improve from 0.63563\n","Epoch 19/2000\n","63/63 [==============================] - 1s 16ms/step - loss: 0.3093 - accuracy: 0.9100 - val_loss: 0.6644 - val_accuracy: 0.7980\n","\n","Epoch 00019: val_loss did not improve from 0.63563\n","Epoch 20/2000\n","63/63 [==============================] - 1s 16ms/step - loss: 0.3020 - accuracy: 0.9030 - val_loss: 0.6526 - val_accuracy: 0.8080\n","\n","Epoch 00020: val_loss did not improve from 0.63563\n","Epoch 21/2000\n","63/63 [==============================] - 1s 16ms/step - loss: 0.2538 - accuracy: 0.9205 - val_loss: 0.7213 - val_accuracy: 0.7760\n","\n","Epoch 00021: val_loss did not improve from 0.63563\n","Epoch 22/2000\n","63/63 [==============================] - 1s 16ms/step - loss: 0.2560 - accuracy: 0.9190 - val_loss: 0.6055 - val_accuracy: 0.8300\n","\n","Epoch 00022: val_loss improved from 0.63563 to 0.60545, saving model to ./save/simple_cnn_best.hdf5\n","Epoch 23/2000\n","63/63 [==============================] - 1s 16ms/step - loss: 0.2445 - accuracy: 0.9245 - val_loss: 0.6577 - val_accuracy: 0.7940\n","\n","Epoch 00023: val_loss did not improve from 0.60545\n","Epoch 24/2000\n","63/63 [==============================] - 1s 16ms/step - loss: 0.2418 - accuracy: 0.9335 - val_loss: 0.6484 - val_accuracy: 0.8080\n","\n","Epoch 00024: val_loss did not improve from 0.60545\n","Epoch 25/2000\n","63/63 [==============================] - 1s 16ms/step - loss: 0.2127 - accuracy: 0.9360 - val_loss: 0.7290 - val_accuracy: 0.8020\n","\n","Epoch 00025: val_loss did not improve from 0.60545\n","Epoch 26/2000\n","63/63 [==============================] - 1s 16ms/step - loss: 0.1920 - accuracy: 0.9425 - val_loss: 0.7021 - val_accuracy: 0.8080\n","\n","Epoch 00026: val_loss did not improve from 0.60545\n","Epoch 27/2000\n","63/63 [==============================] - 1s 16ms/step - loss: 0.1815 - accuracy: 0.9440 - val_loss: 0.6871 - val_accuracy: 0.8080\n","\n","Epoch 00027: val_loss did not improve from 0.60545\n","\n","Epoch 00027: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n","Epoch 28/2000\n","63/63 [==============================] - 1s 16ms/step - loss: 0.1390 - accuracy: 0.9595 - val_loss: 0.6970 - val_accuracy: 0.8180\n","\n","Epoch 00028: val_loss did not improve from 0.60545\n","Epoch 29/2000\n","63/63 [==============================] - 1s 16ms/step - loss: 0.1198 - accuracy: 0.9670 - val_loss: 0.6659 - val_accuracy: 0.8180\n","\n","Epoch 00029: val_loss did not improve from 0.60545\n","Epoch 30/2000\n","63/63 [==============================] - 1s 16ms/step - loss: 0.1105 - accuracy: 0.9670 - val_loss: 0.6931 - val_accuracy: 0.8080\n","\n","Epoch 00030: val_loss did not improve from 0.60545\n","Epoch 31/2000\n","63/63 [==============================] - 1s 16ms/step - loss: 0.1012 - accuracy: 0.9730 - val_loss: 0.6670 - val_accuracy: 0.8280\n","\n","Epoch 00031: val_loss did not improve from 0.60545\n","Epoch 32/2000\n","63/63 [==============================] - 1s 16ms/step - loss: 0.1017 - accuracy: 0.9680 - val_loss: 0.6611 - val_accuracy: 0.8320\n","\n","Epoch 00032: val_loss did not improve from 0.60545\n","\n","Epoch 00032: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n","Epoch 33/2000\n","63/63 [==============================] - 1s 16ms/step - loss: 0.0873 - accuracy: 0.9795 - val_loss: 0.6715 - val_accuracy: 0.8240\n","\n","Epoch 00033: val_loss did not improve from 0.60545\n","Epoch 34/2000\n","63/63 [==============================] - 1s 16ms/step - loss: 0.0844 - accuracy: 0.9755 - val_loss: 0.6764 - val_accuracy: 0.8320\n","\n","Epoch 00034: val_loss did not improve from 0.60545\n","Epoch 35/2000\n","63/63 [==============================] - 1s 16ms/step - loss: 0.0755 - accuracy: 0.9825 - val_loss: 0.6672 - val_accuracy: 0.8340\n","\n","Epoch 00035: val_loss did not improve from 0.60545\n","Epoch 36/2000\n","63/63 [==============================] - 1s 16ms/step - loss: 0.0756 - accuracy: 0.9775 - val_loss: 0.6742 - val_accuracy: 0.8260\n","\n","Epoch 00036: val_loss did not improve from 0.60545\n","Epoch 37/2000\n","63/63 [==============================] - 1s 16ms/step - loss: 0.0787 - accuracy: 0.9795 - val_loss: 0.6591 - val_accuracy: 0.8320\n","\n","Epoch 00037: val_loss did not improve from 0.60545\n","\n","Epoch 00037: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n","Epoch 38/2000\n","63/63 [==============================] - 1s 16ms/step - loss: 0.0688 - accuracy: 0.9805 - val_loss: 0.6670 - val_accuracy: 0.8360\n","\n","Epoch 00038: val_loss did not improve from 0.60545\n","Epoch 39/2000\n","63/63 [==============================] - 1s 16ms/step - loss: 0.0669 - accuracy: 0.9845 - val_loss: 0.6678 - val_accuracy: 0.8340\n","\n","Epoch 00039: val_loss did not improve from 0.60545\n","Epoch 40/2000\n","63/63 [==============================] - 1s 16ms/step - loss: 0.0641 - accuracy: 0.9855 - val_loss: 0.6838 - val_accuracy: 0.8380\n","\n","Epoch 00040: val_loss did not improve from 0.60545\n","Epoch 41/2000\n","63/63 [==============================] - 1s 16ms/step - loss: 0.0568 - accuracy: 0.9880 - val_loss: 0.6908 - val_accuracy: 0.8240\n","\n","Epoch 00041: val_loss did not improve from 0.60545\n","Epoch 42/2000\n","63/63 [==============================] - 1s 16ms/step - loss: 0.0553 - accuracy: 0.9880 - val_loss: 0.6847 - val_accuracy: 0.8340\n","\n","Epoch 00042: val_loss did not improve from 0.60545\n","\n","Epoch 00042: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n","Epoch 43/2000\n","63/63 [==============================] - 1s 16ms/step - loss: 0.0569 - accuracy: 0.9855 - val_loss: 0.6860 - val_accuracy: 0.8400\n","\n","Epoch 00043: val_loss did not improve from 0.60545\n","Epoch 44/2000\n","63/63 [==============================] - 1s 16ms/step - loss: 0.0595 - accuracy: 0.9845 - val_loss: 0.6931 - val_accuracy: 0.8320\n","\n","Epoch 00044: val_loss did not improve from 0.60545\n","Epoch 45/2000\n","63/63 [==============================] - 1s 16ms/step - loss: 0.0546 - accuracy: 0.9890 - val_loss: 0.6846 - val_accuracy: 0.8380\n","\n","Epoch 00045: val_loss did not improve from 0.60545\n","Epoch 46/2000\n","63/63 [==============================] - 1s 16ms/step - loss: 0.0579 - accuracy: 0.9875 - val_loss: 0.6925 - val_accuracy: 0.8400\n","\n","Epoch 00046: val_loss did not improve from 0.60545\n","Epoch 47/2000\n","63/63 [==============================] - 1s 16ms/step - loss: 0.0526 - accuracy: 0.9900 - val_loss: 0.6866 - val_accuracy: 0.8440\n","\n","Epoch 00047: val_loss did not improve from 0.60545\n","\n","Epoch 00047: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n","Epoch 48/2000\n","63/63 [==============================] - 1s 16ms/step - loss: 0.0457 - accuracy: 0.9915 - val_loss: 0.6889 - val_accuracy: 0.8440\n","\n","Epoch 00048: val_loss did not improve from 0.60545\n","Epoch 49/2000\n","63/63 [==============================] - 1s 16ms/step - loss: 0.0501 - accuracy: 0.9920 - val_loss: 0.6930 - val_accuracy: 0.8440\n","\n","Epoch 00049: val_loss did not improve from 0.60545\n","Epoch 50/2000\n","63/63 [==============================] - 1s 16ms/step - loss: 0.0531 - accuracy: 0.9865 - val_loss: 0.6959 - val_accuracy: 0.8420\n","\n","Epoch 00050: val_loss did not improve from 0.60545\n","Epoch 51/2000\n","63/63 [==============================] - 1s 16ms/step - loss: 0.0530 - accuracy: 0.9880 - val_loss: 0.6939 - val_accuracy: 0.8400\n","\n","Epoch 00051: val_loss did not improve from 0.60545\n","Epoch 52/2000\n","63/63 [==============================] - 1s 16ms/step - loss: 0.0522 - accuracy: 0.9900 - val_loss: 0.6950 - val_accuracy: 0.8420\n","\n","Epoch 00052: val_loss did not improve from 0.60545\n","\n","Epoch 00052: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n","Epoch 00052: early stopping\n"]}],"source":["checkpoint_filepath = \"./save/simple_cnn_best.hdf5\"\n","\n","save_best = tf.keras.callbacks.ModelCheckpoint(\n","    filepath=checkpoint_filepath, monitor='val_loss', verbose=1, save_best_only=True,\n","    save_weights_only=True, mode='auto', save_freq='epoch', options=None)\n","\n","lr_scheduler = tf.keras.callbacks.ReduceLROnPlateau(patience = 5,verbose = 1,factor = 0.5) \n","\n","early_stop = tf.keras.callbacks.EarlyStopping(\n","    monitor='val_loss',min_delta=0.0001,\n","    patience=30,verbose=1)\n","\n","history = model.fit(\n","    X_train[:,:,:input_channel],y_train,\n","    epochs=2000,\n","    callbacks=[save_best,early_stop,lr_scheduler],\n","    validation_split=0.2\n","    )"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":["20/20 [==============================] - 0s 5ms/step - loss: 0.5941 - accuracy: 0.8288\n"]},{"output_type":"execute_result","data":{"text/plain":["[0.5940622687339783, 0.8288000226020813]"]},"metadata":{},"execution_count":6}],"source":["model.load_weights(checkpoint_filepath)\n","model.evaluate(X_test[:,:,:input_channel],y_test)\n",""]}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"codemirror_mode":{"name":"ipython","version":2},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython2","version":2},"orig_nbformat":4}}