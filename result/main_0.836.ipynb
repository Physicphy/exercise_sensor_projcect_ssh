{"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import tensorflow as tf\n","import random as rn\n","from my_utils import Workout_dataset, class_weight_dict\n","from my_model import make_CNN_RNN_model\n","\n","import os"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["# seed 고정\n","os.environ['PYTHONHASHSEED'] = str(42)\n","\n","os.environ['TF_DETERMINISTIC_OPS'] = '1'\n","os.environ['TF_CUDNN_DETERMINISTIC'] = '1'\n","\n","tf.random.set_seed(42)\n","np.random.seed(42)\n","rn.seed(42)"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["def scheduler(epoch, lr):\n","    if (epoch>20) and (lr > 0.00001):\n","        lr = lr*0.9\n","        return lr\n","    else:\n","        return lr\n","\n","lr_scheduler = tf.keras.callbacks.LearningRateScheduler(scheduler)\n","\n","train_dir = './data/train'\n","label_dir = './data/data_y_train.csv'\n","test_dir = './data/test'\n","test_label_dir = './data/data_y_test.csv'\n","checkpoint_filepath = \"./save/cnn_gru_best.hdf5\"\n","\n","BATCH_SIZE = 64\n","\n","train_loader = Workout_dataset(\n","    train_dir, label_dir, mode='Train',\n","    fold=0, batch_size=BATCH_SIZE, augment=True, shuffle=True)\n","\n","valid_loader = Workout_dataset(\n","    train_dir, label_dir, mode='Valid',\n","    fold=0, batch_size=16, shuffle=True)\n","\n","test_loader = Workout_dataset(\n","    test_dir, test_label_dir, mode='Test',\n","    batch_size=625, shuffle=False)\n",""]},{"cell_type":"code","execution_count":4,"metadata":{"tags":["outputPrepend"]},"outputs":[{"output_type":"stream","name":"stdout","text":["__________________________________________________________________________________\n","leaky_re_lu_5 (LeakyReLU)       (None, 300, 20)      0           gru_2[0][0]                      \n","__________________________________________________________________________________________________\n","leaky_re_lu_13 (LeakyReLU)      (None, 300, 20)      0           gru_6[0][0]                      \n","__________________________________________________________________________________________________\n","leaky_re_lu_17 (LeakyReLU)      (None, 300, 20)      0           gru_8[0][0]                      \n","__________________________________________________________________________________________________\n","leaky_re_lu_9 (LeakyReLU)       (None, 300, 20)      0           gru_4[0][0]                      \n","__________________________________________________________________________________________________\n","batch_normalization_1 (BatchNor (None, 300, 20)      80          leaky_re_lu_1[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_5 (BatchNor (None, 300, 20)      80          leaky_re_lu_5[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_13 (BatchNo (None, 300, 20)      80          leaky_re_lu_13[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_17 (BatchNo (None, 300, 20)      80          leaky_re_lu_17[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_9 (BatchNor (None, 300, 20)      80          leaky_re_lu_9[0][0]              \n","__________________________________________________________________________________________________\n","conv1d_1 (Conv1D)               (None, 150, 60)      3660        batch_normalization_1[0][0]      \n","__________________________________________________________________________________________________\n","conv1d_3 (Conv1D)               (None, 150, 60)      3660        batch_normalization_5[0][0]      \n","__________________________________________________________________________________________________\n","conv1d_7 (Conv1D)               (None, 150, 60)      3660        batch_normalization_13[0][0]     \n","__________________________________________________________________________________________________\n","conv1d_9 (Conv1D)               (None, 150, 60)      3660        batch_normalization_17[0][0]     \n","__________________________________________________________________________________________________\n","conv1d_5 (Conv1D)               (None, 150, 60)      3660        batch_normalization_9[0][0]      \n","__________________________________________________________________________________________________\n","leaky_re_lu_2 (LeakyReLU)       (None, 150, 60)      0           conv1d_1[0][0]                   \n","__________________________________________________________________________________________________\n","leaky_re_lu_6 (LeakyReLU)       (None, 150, 60)      0           conv1d_3[0][0]                   \n","__________________________________________________________________________________________________\n","leaky_re_lu_14 (LeakyReLU)      (None, 150, 60)      0           conv1d_7[0][0]                   \n","__________________________________________________________________________________________________\n","leaky_re_lu_18 (LeakyReLU)      (None, 150, 60)      0           conv1d_9[0][0]                   \n","__________________________________________________________________________________________________\n","leaky_re_lu_10 (LeakyReLU)      (None, 150, 60)      0           conv1d_5[0][0]                   \n","__________________________________________________________________________________________________\n","batch_normalization_2 (BatchNor (None, 150, 60)      240         leaky_re_lu_2[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_6 (BatchNor (None, 150, 60)      240         leaky_re_lu_6[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_14 (BatchNo (None, 150, 60)      240         leaky_re_lu_14[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_18 (BatchNo (None, 150, 60)      240         leaky_re_lu_18[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_10 (BatchNo (None, 150, 60)      240         leaky_re_lu_10[0][0]             \n","__________________________________________________________________________________________________\n","gru_1 (GRU)                     (None, 150, 60)      21960       batch_normalization_2[0][0]      \n","__________________________________________________________________________________________________\n","gru_3 (GRU)                     (None, 150, 60)      21960       batch_normalization_6[0][0]      \n","__________________________________________________________________________________________________\n","gru_7 (GRU)                     (None, 150, 60)      21960       batch_normalization_14[0][0]     \n","__________________________________________________________________________________________________\n","gru_9 (GRU)                     (None, 150, 60)      21960       batch_normalization_18[0][0]     \n","__________________________________________________________________________________________________\n","gru_5 (GRU)                     (None, 150, 60)      21960       batch_normalization_10[0][0]     \n","__________________________________________________________________________________________________\n","leaky_re_lu_3 (LeakyReLU)       (None, 150, 60)      0           gru_1[0][0]                      \n","__________________________________________________________________________________________________\n","leaky_re_lu_7 (LeakyReLU)       (None, 150, 60)      0           gru_3[0][0]                      \n","__________________________________________________________________________________________________\n","leaky_re_lu_15 (LeakyReLU)      (None, 150, 60)      0           gru_7[0][0]                      \n","__________________________________________________________________________________________________\n","leaky_re_lu_19 (LeakyReLU)      (None, 150, 60)      0           gru_9[0][0]                      \n","__________________________________________________________________________________________________\n","leaky_re_lu_11 (LeakyReLU)      (None, 150, 60)      0           gru_5[0][0]                      \n","__________________________________________________________________________________________________\n","batch_normalization_3 (BatchNor (None, 150, 60)      240         leaky_re_lu_3[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_7 (BatchNor (None, 150, 60)      240         leaky_re_lu_7[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_15 (BatchNo (None, 150, 60)      240         leaky_re_lu_15[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_19 (BatchNo (None, 150, 60)      240         leaky_re_lu_19[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_11 (BatchNo (None, 150, 60)      240         leaky_re_lu_11[0][0]             \n","__________________________________________________________________________________________________\n","concatenate_5 (Concatenate)     (None, 150, 300)     0           batch_normalization_3[0][0]      \n","                                                                 batch_normalization_7[0][0]      \n","                                                                 batch_normalization_15[0][0]     \n","                                                                 batch_normalization_19[0][0]     \n","                                                                 batch_normalization_11[0][0]     \n","__________________________________________________________________________________________________\n","conv1d_11 (Conv1D)              (None, 150, 60)      162060      concatenate_5[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_20 (BatchNo (None, 150, 60)      240         conv1d_11[0][0]                  \n","__________________________________________________________________________________________________\n","leaky_re_lu_20 (LeakyReLU)      (None, 150, 60)      0           batch_normalization_20[0][0]     \n","__________________________________________________________________________________________________\n","conv1d_12 (Conv1D)              (None, 150, 120)     21720       leaky_re_lu_20[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_21 (BatchNo (None, 150, 120)     480         conv1d_12[0][0]                  \n","__________________________________________________________________________________________________\n","leaky_re_lu_21 (LeakyReLU)      (None, 150, 120)     0           batch_normalization_21[0][0]     \n","__________________________________________________________________________________________________\n","conv1d_13 (Conv1D)              (None, 150, 60)      21660       leaky_re_lu_21[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_22 (BatchNo (None, 150, 60)      240         conv1d_13[0][0]                  \n","__________________________________________________________________________________________________\n","leaky_re_lu_22 (LeakyReLU)      (None, 150, 60)      0           batch_normalization_22[0][0]     \n","__________________________________________________________________________________________________\n","conv1d_10 (Conv1D)              (None, 150, 60)      162060      concatenate_5[0][0]              \n","__________________________________________________________________________________________________\n","add (Add)                       (None, 150, 60)      0           leaky_re_lu_22[0][0]             \n","                                                                 conv1d_10[0][0]                  \n","__________________________________________________________________________________________________\n","conv1d_14 (Conv1D)              (None, 150, 60)      32460       add[0][0]                        \n","__________________________________________________________________________________________________\n","batch_normalization_23 (BatchNo (None, 150, 60)      240         conv1d_14[0][0]                  \n","__________________________________________________________________________________________________\n","leaky_re_lu_23 (LeakyReLU)      (None, 150, 60)      0           batch_normalization_23[0][0]     \n","__________________________________________________________________________________________________\n","conv1d_15 (Conv1D)              (None, 150, 120)     21720       leaky_re_lu_23[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_24 (BatchNo (None, 150, 120)     480         conv1d_15[0][0]                  \n","__________________________________________________________________________________________________\n","leaky_re_lu_24 (LeakyReLU)      (None, 150, 120)     0           batch_normalization_24[0][0]     \n","__________________________________________________________________________________________________\n","conv1d_16 (Conv1D)              (None, 150, 60)      21660       leaky_re_lu_24[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_25 (BatchNo (None, 150, 60)      240         conv1d_16[0][0]                  \n","__________________________________________________________________________________________________\n","leaky_re_lu_25 (LeakyReLU)      (None, 150, 60)      0           batch_normalization_25[0][0]     \n","__________________________________________________________________________________________________\n","add_1 (Add)                     (None, 150, 60)      0           leaky_re_lu_25[0][0]             \n","                                                                 add[0][0]                        \n","__________________________________________________________________________________________________\n","conv1d_17 (Conv1D)              (None, 150, 60)      32460       add_1[0][0]                      \n","__________________________________________________________________________________________________\n","batch_normalization_26 (BatchNo (None, 150, 60)      240         conv1d_17[0][0]                  \n","__________________________________________________________________________________________________\n","leaky_re_lu_26 (LeakyReLU)      (None, 150, 60)      0           batch_normalization_26[0][0]     \n","__________________________________________________________________________________________________\n","conv1d_18 (Conv1D)              (None, 150, 120)     21720       leaky_re_lu_26[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_27 (BatchNo (None, 150, 120)     480         conv1d_18[0][0]                  \n","__________________________________________________________________________________________________\n","leaky_re_lu_27 (LeakyReLU)      (None, 150, 120)     0           batch_normalization_27[0][0]     \n","__________________________________________________________________________________________________\n","conv1d_19 (Conv1D)              (None, 150, 60)      21660       leaky_re_lu_27[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_28 (BatchNo (None, 150, 60)      240         conv1d_19[0][0]                  \n","__________________________________________________________________________________________________\n","leaky_re_lu_28 (LeakyReLU)      (None, 150, 60)      0           batch_normalization_28[0][0]     \n","__________________________________________________________________________________________________\n","add_2 (Add)                     (None, 150, 60)      0           leaky_re_lu_28[0][0]             \n","                                                                 add_1[0][0]                      \n","__________________________________________________________________________________________________\n","conv1d_20 (Conv1D)              (None, 150, 60)      32460       add_2[0][0]                      \n","__________________________________________________________________________________________________\n","batch_normalization_29 (BatchNo (None, 150, 60)      240         conv1d_20[0][0]                  \n","__________________________________________________________________________________________________\n","leaky_re_lu_29 (LeakyReLU)      (None, 150, 60)      0           batch_normalization_29[0][0]     \n","__________________________________________________________________________________________________\n","conv1d_21 (Conv1D)              (None, 150, 120)     21720       leaky_re_lu_29[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_30 (BatchNo (None, 150, 120)     480         conv1d_21[0][0]                  \n","__________________________________________________________________________________________________\n","leaky_re_lu_30 (LeakyReLU)      (None, 150, 120)     0           batch_normalization_30[0][0]     \n","__________________________________________________________________________________________________\n","conv1d_22 (Conv1D)              (None, 150, 60)      21660       leaky_re_lu_30[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_31 (BatchNo (None, 150, 60)      240         conv1d_22[0][0]                  \n","__________________________________________________________________________________________________\n","leaky_re_lu_31 (LeakyReLU)      (None, 150, 60)      0           batch_normalization_31[0][0]     \n","__________________________________________________________________________________________________\n","add_3 (Add)                     (None, 150, 60)      0           leaky_re_lu_31[0][0]             \n","                                                                 add_2[0][0]                      \n","__________________________________________________________________________________________________\n","conv1d_23 (Conv1D)              (None, 150, 60)      32460       add_3[0][0]                      \n","__________________________________________________________________________________________________\n","batch_normalization_32 (BatchNo (None, 150, 60)      240         conv1d_23[0][0]                  \n","__________________________________________________________________________________________________\n","leaky_re_lu_32 (LeakyReLU)      (None, 150, 60)      0           batch_normalization_32[0][0]     \n","__________________________________________________________________________________________________\n","conv1d_24 (Conv1D)              (None, 150, 120)     21720       leaky_re_lu_32[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_33 (BatchNo (None, 150, 120)     480         conv1d_24[0][0]                  \n","__________________________________________________________________________________________________\n","leaky_re_lu_33 (LeakyReLU)      (None, 150, 120)     0           batch_normalization_33[0][0]     \n","__________________________________________________________________________________________________\n","conv1d_25 (Conv1D)              (None, 150, 60)      21660       leaky_re_lu_33[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_34 (BatchNo (None, 150, 60)      240         conv1d_25[0][0]                  \n","__________________________________________________________________________________________________\n","leaky_re_lu_34 (LeakyReLU)      (None, 150, 60)      0           batch_normalization_34[0][0]     \n","__________________________________________________________________________________________________\n","add_4 (Add)                     (None, 150, 60)      0           leaky_re_lu_34[0][0]             \n","                                                                 add_3[0][0]                      \n","__________________________________________________________________________________________________\n","batch_normalization_35 (BatchNo (None, 150, 60)      240         add_4[0][0]                      \n","__________________________________________________________________________________________________\n","global_average_pooling1d (Globa (None, 60)           0           batch_normalization_35[0][0]     \n","__________________________________________________________________________________________________\n","dense (Dense)                   (None, 61)           3721        global_average_pooling1d[0][0]   \n","==================================================================================================\n","Total params: 825,051\n","Trainable params: 821,031\n","Non-trainable params: 4,020\n","__________________________________________________________________________________________________\n","/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"]}],"source":["model = make_CNN_RNN_model(\n","    lr = 0.001,\n","    leakyrelu_alpha = 0.2,\n","    input_kernels = 10,\n","    input_kernel_width = 3,\n","    res_kernels = 60,\n","    res_kernel_width = 3,\n","    res_regularize_coeff=0.1, #0.2\n","    res_num = 5, #3\n","    )\n","\n","model.summary()"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":["WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/array_ops.py:5049: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n","Instructions for updating:\n","The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n","/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1940: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n","  warnings.warn('`Model.fit_generator` is deprecated and '\n","Epoch 1/2000\n","34/34 [==============================] - 31s 264ms/step - loss: 189.7364 - accuracy: 0.3529 - val_loss: 127.2216 - val_accuracy: 0.4453\n","\n","Epoch 00001: val_loss improved from inf to 127.22160, saving model to ./save/cnn_gru_best.hdf5\n","Epoch 2/2000\n","34/34 [==============================] - 6s 167ms/step - loss: 95.1904 - accuracy: 0.5312 - val_loss: 65.4722 - val_accuracy: 0.4531\n","\n","Epoch 00002: val_loss improved from 127.22160 to 65.47216, saving model to ./save/cnn_gru_best.hdf5\n","Epoch 3/2000\n","34/34 [==============================] - 6s 167ms/step - loss: 50.4103 - accuracy: 0.6172 - val_loss: 35.7351 - val_accuracy: 0.4414\n","\n","Epoch 00003: val_loss improved from 65.47216 to 35.73509, saving model to ./save/cnn_gru_best.hdf5\n","Epoch 4/2000\n","34/34 [==============================] - 6s 168ms/step - loss: 28.1882 - accuracy: 0.6792 - val_loss: 20.6764 - val_accuracy: 0.4648\n","\n","Epoch 00004: val_loss improved from 35.73509 to 20.67635, saving model to ./save/cnn_gru_best.hdf5\n","Epoch 5/2000\n","34/34 [==============================] - 6s 166ms/step - loss: 16.8875 - accuracy: 0.6815 - val_loss: 12.9691 - val_accuracy: 0.4570\n","\n","Epoch 00005: val_loss improved from 20.67635 to 12.96908, saving model to ./save/cnn_gru_best.hdf5\n","Epoch 6/2000\n","34/34 [==============================] - 6s 169ms/step - loss: 10.7694 - accuracy: 0.6962 - val_loss: 9.5967 - val_accuracy: 0.4570\n","\n","Epoch 00006: val_loss improved from 12.96908 to 9.59674, saving model to ./save/cnn_gru_best.hdf5\n","Epoch 7/2000\n","34/34 [==============================] - 6s 169ms/step - loss: 7.4189 - accuracy: 0.7059 - val_loss: 7.0828 - val_accuracy: 0.4570\n","\n","Epoch 00007: val_loss improved from 9.59674 to 7.08276, saving model to ./save/cnn_gru_best.hdf5\n","Epoch 8/2000\n","34/34 [==============================] - 6s 177ms/step - loss: 5.6700 - accuracy: 0.7137 - val_loss: 5.7802 - val_accuracy: 0.4531\n","\n","Epoch 00008: val_loss improved from 7.08276 to 5.78015, saving model to ./save/cnn_gru_best.hdf5\n","Epoch 9/2000\n","34/34 [==============================] - 6s 167ms/step - loss: 4.8696 - accuracy: 0.7013 - val_loss: 6.0221 - val_accuracy: 0.4453\n","\n","Epoch 00009: val_loss did not improve from 5.78015\n","Epoch 10/2000\n","34/34 [==============================] - 6s 167ms/step - loss: 4.1238 - accuracy: 0.7316 - val_loss: 7.3711 - val_accuracy: 0.0117\n","\n","Epoch 00010: val_loss did not improve from 5.78015\n","Epoch 11/2000\n","34/34 [==============================] - 6s 167ms/step - loss: 3.7616 - accuracy: 0.7408 - val_loss: 6.5689 - val_accuracy: 0.0156\n","\n","Epoch 00011: val_loss did not improve from 5.78015\n","Epoch 12/2000\n","34/34 [==============================] - 6s 168ms/step - loss: 3.4338 - accuracy: 0.7606 - val_loss: 5.2196 - val_accuracy: 0.2773\n","\n","Epoch 00012: val_loss improved from 5.78015 to 5.21963, saving model to ./save/cnn_gru_best.hdf5\n","Epoch 13/2000\n","34/34 [==============================] - 6s 165ms/step - loss: 3.4092 - accuracy: 0.7445 - val_loss: 6.2699 - val_accuracy: 0.0859\n","\n","Epoch 00013: val_loss did not improve from 5.21963\n","Epoch 14/2000\n","34/34 [==============================] - 6s 164ms/step - loss: 3.1825 - accuracy: 0.7551 - val_loss: 6.6519 - val_accuracy: 0.0781\n","\n","Epoch 00014: val_loss did not improve from 5.21963\n","Epoch 15/2000\n","34/34 [==============================] - 6s 166ms/step - loss: 3.0184 - accuracy: 0.7656 - val_loss: 4.8186 - val_accuracy: 0.2188\n","\n","Epoch 00015: val_loss improved from 5.21963 to 4.81858, saving model to ./save/cnn_gru_best.hdf5\n","Epoch 16/2000\n","34/34 [==============================] - 6s 167ms/step - loss: 2.9367 - accuracy: 0.7734 - val_loss: 3.7279 - val_accuracy: 0.5039\n","\n","Epoch 00016: val_loss improved from 4.81858 to 3.72788, saving model to ./save/cnn_gru_best.hdf5\n","Epoch 17/2000\n","34/34 [==============================] - 6s 165ms/step - loss: 3.0604 - accuracy: 0.7656 - val_loss: 3.2622 - val_accuracy: 0.5039\n","\n","Epoch 00017: val_loss improved from 3.72788 to 3.26215, saving model to ./save/cnn_gru_best.hdf5\n","Epoch 18/2000\n","34/34 [==============================] - 6s 167ms/step - loss: 2.7157 - accuracy: 0.7840 - val_loss: 2.9577 - val_accuracy: 0.4805\n","\n","Epoch 00018: val_loss improved from 3.26215 to 2.95766, saving model to ./save/cnn_gru_best.hdf5\n","Epoch 19/2000\n","34/34 [==============================] - 6s 170ms/step - loss: 2.9785 - accuracy: 0.7661 - val_loss: 2.6378 - val_accuracy: 0.5742\n","\n","Epoch 00019: val_loss improved from 2.95766 to 2.63776, saving model to ./save/cnn_gru_best.hdf5\n","Epoch 20/2000\n","34/34 [==============================] - 6s 171ms/step - loss: 2.8096 - accuracy: 0.7881 - val_loss: 3.4285 - val_accuracy: 0.4375\n","\n","Epoch 00020: val_loss did not improve from 2.63776\n","Epoch 21/2000\n","34/34 [==============================] - 6s 166ms/step - loss: 2.8043 - accuracy: 0.7826 - val_loss: 2.2144 - val_accuracy: 0.6406\n","\n","Epoch 00021: val_loss improved from 2.63776 to 2.21444, saving model to ./save/cnn_gru_best.hdf5\n","Epoch 22/2000\n","34/34 [==============================] - 6s 165ms/step - loss: 2.5708 - accuracy: 0.7996 - val_loss: 1.9837 - val_accuracy: 0.6367\n","\n","Epoch 00022: val_loss improved from 2.21444 to 1.98369, saving model to ./save/cnn_gru_best.hdf5\n","Epoch 23/2000\n","34/34 [==============================] - 6s 165ms/step - loss: 2.2589 - accuracy: 0.8286 - val_loss: 2.4252 - val_accuracy: 0.5156\n","\n","Epoch 00023: val_loss did not improve from 1.98369\n","Epoch 24/2000\n","34/34 [==============================] - 6s 167ms/step - loss: 2.1601 - accuracy: 0.8263 - val_loss: 1.7533 - val_accuracy: 0.6680\n","\n","Epoch 00024: val_loss improved from 1.98369 to 1.75330, saving model to ./save/cnn_gru_best.hdf5\n","Epoch 25/2000\n","34/34 [==============================] - 6s 166ms/step - loss: 2.1096 - accuracy: 0.8286 - val_loss: 1.7334 - val_accuracy: 0.7188\n","\n","Epoch 00025: val_loss improved from 1.75330 to 1.73343, saving model to ./save/cnn_gru_best.hdf5\n","Epoch 26/2000\n","34/34 [==============================] - 6s 166ms/step - loss: 1.9221 - accuracy: 0.8548 - val_loss: 1.4799 - val_accuracy: 0.7227\n","\n","Epoch 00026: val_loss improved from 1.73343 to 1.47987, saving model to ./save/cnn_gru_best.hdf5\n","Epoch 27/2000\n","34/34 [==============================] - 6s 168ms/step - loss: 1.9286 - accuracy: 0.8341 - val_loss: 1.4986 - val_accuracy: 0.7461\n","\n","Epoch 00027: val_loss did not improve from 1.47987\n","Epoch 28/2000\n","34/34 [==============================] - 6s 168ms/step - loss: 1.7943 - accuracy: 0.8456 - val_loss: 1.3487 - val_accuracy: 0.7422\n","\n","Epoch 00028: val_loss improved from 1.47987 to 1.34868, saving model to ./save/cnn_gru_best.hdf5\n","Epoch 29/2000\n","34/34 [==============================] - 6s 168ms/step - loss: 1.6904 - accuracy: 0.8483 - val_loss: 1.3265 - val_accuracy: 0.7422\n","\n","Epoch 00029: val_loss improved from 1.34868 to 1.32648, saving model to ./save/cnn_gru_best.hdf5\n","Epoch 30/2000\n","34/34 [==============================] - 6s 167ms/step - loss: 1.7152 - accuracy: 0.8543 - val_loss: 1.3585 - val_accuracy: 0.7148\n","\n","Epoch 00030: val_loss did not improve from 1.32648\n","Epoch 31/2000\n","34/34 [==============================] - 6s 166ms/step - loss: 1.6247 - accuracy: 0.8566 - val_loss: 1.2558 - val_accuracy: 0.7344\n","\n","Epoch 00031: val_loss improved from 1.32648 to 1.25583, saving model to ./save/cnn_gru_best.hdf5\n","Epoch 32/2000\n","34/34 [==============================] - 6s 166ms/step - loss: 1.5888 - accuracy: 0.8644 - val_loss: 1.4040 - val_accuracy: 0.7266\n","\n","Epoch 00032: val_loss did not improve from 1.25583\n","Epoch 33/2000\n","34/34 [==============================] - 6s 169ms/step - loss: 1.5805 - accuracy: 0.8608 - val_loss: 1.2406 - val_accuracy: 0.7500\n","\n","Epoch 00033: val_loss improved from 1.25583 to 1.24065, saving model to ./save/cnn_gru_best.hdf5\n","Epoch 34/2000\n","34/34 [==============================] - 6s 168ms/step - loss: 1.5062 - accuracy: 0.8653 - val_loss: 1.2936 - val_accuracy: 0.7031\n","\n","Epoch 00034: val_loss did not improve from 1.24065\n","Epoch 35/2000\n","34/34 [==============================] - 6s 168ms/step - loss: 1.3251 - accuracy: 0.8879 - val_loss: 1.1707 - val_accuracy: 0.7344\n","\n","Epoch 00035: val_loss improved from 1.24065 to 1.17071, saving model to ./save/cnn_gru_best.hdf5\n","Epoch 36/2000\n","34/34 [==============================] - 6s 169ms/step - loss: 1.2957 - accuracy: 0.8925 - val_loss: 1.0909 - val_accuracy: 0.7422\n","\n","Epoch 00036: val_loss improved from 1.17071 to 1.09089, saving model to ./save/cnn_gru_best.hdf5\n","Epoch 37/2000\n","34/34 [==============================] - 6s 169ms/step - loss: 1.1981 - accuracy: 0.8984 - val_loss: 1.2910 - val_accuracy: 0.7148\n","\n","Epoch 00037: val_loss did not improve from 1.09089\n","Epoch 38/2000\n","34/34 [==============================] - 6s 164ms/step - loss: 1.4468 - accuracy: 0.8580 - val_loss: 1.1283 - val_accuracy: 0.7578\n","\n","Epoch 00038: val_loss did not improve from 1.09089\n","Epoch 39/2000\n","34/34 [==============================] - 6s 166ms/step - loss: 1.2140 - accuracy: 0.8929 - val_loss: 1.0992 - val_accuracy: 0.7539\n","\n","Epoch 00039: val_loss did not improve from 1.09089\n","Epoch 40/2000\n","34/34 [==============================] - 6s 168ms/step - loss: 1.2035 - accuracy: 0.8943 - val_loss: 1.0076 - val_accuracy: 0.7812\n","\n","Epoch 00040: val_loss improved from 1.09089 to 1.00758, saving model to ./save/cnn_gru_best.hdf5\n","Epoch 41/2000\n","34/34 [==============================] - 6s 166ms/step - loss: 1.2510 - accuracy: 0.8897 - val_loss: 1.0648 - val_accuracy: 0.7656\n","\n","Epoch 00041: val_loss did not improve from 1.00758\n","Epoch 42/2000\n","34/34 [==============================] - 6s 167ms/step - loss: 1.1559 - accuracy: 0.9035 - val_loss: 0.9854 - val_accuracy: 0.7773\n","\n","Epoch 00042: val_loss improved from 1.00758 to 0.98537, saving model to ./save/cnn_gru_best.hdf5\n","Epoch 43/2000\n","34/34 [==============================] - 6s 167ms/step - loss: 1.0250 - accuracy: 0.9104 - val_loss: 0.9527 - val_accuracy: 0.7734\n","\n","Epoch 00043: val_loss improved from 0.98537 to 0.95268, saving model to ./save/cnn_gru_best.hdf5\n","Epoch 44/2000\n","34/34 [==============================] - 6s 165ms/step - loss: 1.1304 - accuracy: 0.9058 - val_loss: 1.0401 - val_accuracy: 0.7656\n","\n","Epoch 00044: val_loss did not improve from 0.95268\n","Epoch 45/2000\n","34/34 [==============================] - 6s 168ms/step - loss: 1.1007 - accuracy: 0.9099 - val_loss: 1.0308 - val_accuracy: 0.7656\n","\n","Epoch 00045: val_loss did not improve from 0.95268\n","Epoch 46/2000\n","34/34 [==============================] - 6s 166ms/step - loss: 1.0229 - accuracy: 0.9154 - val_loss: 1.0481 - val_accuracy: 0.7539\n","\n","Epoch 00046: val_loss did not improve from 0.95268\n","Epoch 47/2000\n","34/34 [==============================] - 6s 165ms/step - loss: 1.0824 - accuracy: 0.9113 - val_loss: 0.9845 - val_accuracy: 0.7773\n","\n","Epoch 00047: val_loss did not improve from 0.95268\n","Epoch 48/2000\n","34/34 [==============================] - 6s 166ms/step - loss: 1.0847 - accuracy: 0.9076 - val_loss: 1.0326 - val_accuracy: 0.7500\n","\n","Epoch 00048: val_loss did not improve from 0.95268\n","Epoch 49/2000\n","34/34 [==============================] - 6s 164ms/step - loss: 1.0379 - accuracy: 0.9081 - val_loss: 0.9844 - val_accuracy: 0.7734\n","\n","Epoch 00049: val_loss did not improve from 0.95268\n","Epoch 50/2000\n","34/34 [==============================] - 6s 166ms/step - loss: 0.9856 - accuracy: 0.9145 - val_loss: 0.9560 - val_accuracy: 0.7891\n","\n","Epoch 00050: val_loss did not improve from 0.95268\n","Epoch 51/2000\n","34/34 [==============================] - 6s 165ms/step - loss: 1.0023 - accuracy: 0.9062 - val_loss: 0.9985 - val_accuracy: 0.7461\n","\n","Epoch 00051: val_loss did not improve from 0.95268\n","Epoch 52/2000\n","34/34 [==============================] - 6s 164ms/step - loss: 1.0147 - accuracy: 0.9122 - val_loss: 1.0031 - val_accuracy: 0.7539\n","\n","Epoch 00052: val_loss did not improve from 0.95268\n","Epoch 53/2000\n","34/34 [==============================] - 6s 163ms/step - loss: 0.9054 - accuracy: 0.9311 - val_loss: 0.9251 - val_accuracy: 0.8008\n","\n","Epoch 00053: val_loss improved from 0.95268 to 0.92510, saving model to ./save/cnn_gru_best.hdf5\n","Epoch 54/2000\n","34/34 [==============================] - 6s 166ms/step - loss: 0.9933 - accuracy: 0.9122 - val_loss: 0.9770 - val_accuracy: 0.7773\n","\n","Epoch 00054: val_loss did not improve from 0.92510\n","Epoch 55/2000\n","34/34 [==============================] - 6s 168ms/step - loss: 1.0279 - accuracy: 0.9044 - val_loss: 0.9986 - val_accuracy: 0.7617\n","\n","Epoch 00055: val_loss did not improve from 0.92510\n","Epoch 56/2000\n","34/34 [==============================] - 6s 169ms/step - loss: 0.9802 - accuracy: 0.9131 - val_loss: 0.9557 - val_accuracy: 0.7812\n","\n","Epoch 00056: val_loss did not improve from 0.92510\n","Epoch 57/2000\n","34/34 [==============================] - 6s 167ms/step - loss: 0.8956 - accuracy: 0.9219 - val_loss: 0.9348 - val_accuracy: 0.7773\n","\n","Epoch 00057: val_loss did not improve from 0.92510\n","Epoch 58/2000\n","34/34 [==============================] - 6s 168ms/step - loss: 0.8800 - accuracy: 0.9223 - val_loss: 0.9411 - val_accuracy: 0.7852\n","\n","Epoch 00058: val_loss did not improve from 0.92510\n","Epoch 59/2000\n","34/34 [==============================] - 6s 169ms/step - loss: 0.8680 - accuracy: 0.9306 - val_loss: 0.9460 - val_accuracy: 0.7773\n","\n","Epoch 00059: val_loss did not improve from 0.92510\n","Epoch 60/2000\n","34/34 [==============================] - 6s 166ms/step - loss: 0.8338 - accuracy: 0.9223 - val_loss: 0.9289 - val_accuracy: 0.7812\n","\n","Epoch 00060: val_loss did not improve from 0.92510\n","Epoch 61/2000\n","34/34 [==============================] - 6s 169ms/step - loss: 0.7563 - accuracy: 0.9435 - val_loss: 0.8558 - val_accuracy: 0.8047\n","\n","Epoch 00061: val_loss improved from 0.92510 to 0.85581, saving model to ./save/cnn_gru_best.hdf5\n","Epoch 62/2000\n","34/34 [==============================] - 6s 170ms/step - loss: 0.8278 - accuracy: 0.9306 - val_loss: 0.9410 - val_accuracy: 0.7773\n","\n","Epoch 00062: val_loss did not improve from 0.85581\n","Epoch 63/2000\n","34/34 [==============================] - 6s 167ms/step - loss: 0.7963 - accuracy: 0.9320 - val_loss: 0.9001 - val_accuracy: 0.8047\n","\n","Epoch 00063: val_loss did not improve from 0.85581\n","Epoch 64/2000\n","34/34 [==============================] - 6s 167ms/step - loss: 0.7780 - accuracy: 0.9357 - val_loss: 0.9127 - val_accuracy: 0.7930\n","\n","Epoch 00064: val_loss did not improve from 0.85581\n","Epoch 65/2000\n","34/34 [==============================] - 6s 168ms/step - loss: 0.8561 - accuracy: 0.9315 - val_loss: 0.9173 - val_accuracy: 0.7969\n","\n","Epoch 00065: val_loss did not improve from 0.85581\n","Epoch 66/2000\n","34/34 [==============================] - 6s 167ms/step - loss: 0.8493 - accuracy: 0.9237 - val_loss: 0.9092 - val_accuracy: 0.8008\n","\n","Epoch 00066: val_loss did not improve from 0.85581\n","Epoch 67/2000\n","34/34 [==============================] - 6s 168ms/step - loss: 0.7796 - accuracy: 0.9426 - val_loss: 0.9176 - val_accuracy: 0.7969\n","\n","Epoch 00067: val_loss did not improve from 0.85581\n","Epoch 68/2000\n","34/34 [==============================] - 6s 171ms/step - loss: 0.8818 - accuracy: 0.9210 - val_loss: 0.9074 - val_accuracy: 0.7969\n","\n","Epoch 00068: val_loss did not improve from 0.85581\n","Epoch 69/2000\n","34/34 [==============================] - 6s 168ms/step - loss: 0.9331 - accuracy: 0.9127 - val_loss: 0.8825 - val_accuracy: 0.7930\n","\n","Epoch 00069: val_loss did not improve from 0.85581\n","Epoch 70/2000\n","34/34 [==============================] - 6s 166ms/step - loss: 0.8474 - accuracy: 0.9292 - val_loss: 0.9145 - val_accuracy: 0.7969\n","\n","Epoch 00070: val_loss did not improve from 0.85581\n","Epoch 71/2000\n","34/34 [==============================] - 6s 170ms/step - loss: 0.8171 - accuracy: 0.9343 - val_loss: 0.9287 - val_accuracy: 0.7930\n","\n","Epoch 00071: val_loss did not improve from 0.85581\n","Epoch 72/2000\n","34/34 [==============================] - 6s 176ms/step - loss: 0.7273 - accuracy: 0.9398 - val_loss: 0.9044 - val_accuracy: 0.8047\n","\n","Epoch 00072: val_loss did not improve from 0.85581\n","Epoch 73/2000\n","34/34 [==============================] - 6s 168ms/step - loss: 0.7303 - accuracy: 0.9416 - val_loss: 0.9149 - val_accuracy: 0.7891\n","\n","Epoch 00073: val_loss did not improve from 0.85581\n","Epoch 74/2000\n","34/34 [==============================] - 6s 170ms/step - loss: 0.7726 - accuracy: 0.9329 - val_loss: 0.8898 - val_accuracy: 0.8164\n","\n","Epoch 00074: val_loss did not improve from 0.85581\n","Epoch 75/2000\n","34/34 [==============================] - 6s 170ms/step - loss: 0.8819 - accuracy: 0.9210 - val_loss: 0.9516 - val_accuracy: 0.7812\n","\n","Epoch 00075: val_loss did not improve from 0.85581\n","Epoch 76/2000\n","34/34 [==============================] - 6s 169ms/step - loss: 0.8087 - accuracy: 0.9288 - val_loss: 0.8944 - val_accuracy: 0.7969\n","\n","Epoch 00076: val_loss did not improve from 0.85581\n","Epoch 77/2000\n","34/34 [==============================] - 6s 169ms/step - loss: 0.8015 - accuracy: 0.9315 - val_loss: 0.9229 - val_accuracy: 0.7891\n","\n","Epoch 00077: val_loss did not improve from 0.85581\n","Epoch 78/2000\n","34/34 [==============================] - 6s 171ms/step - loss: 0.8889 - accuracy: 0.9306 - val_loss: 0.8721 - val_accuracy: 0.8086\n","\n","Epoch 00078: val_loss did not improve from 0.85581\n","Epoch 79/2000\n","34/34 [==============================] - 6s 171ms/step - loss: 0.7703 - accuracy: 0.9380 - val_loss: 0.9154 - val_accuracy: 0.7852\n","\n","Epoch 00079: val_loss did not improve from 0.85581\n","Epoch 80/2000\n","34/34 [==============================] - 6s 173ms/step - loss: 0.8050 - accuracy: 0.9347 - val_loss: 0.8966 - val_accuracy: 0.7930\n","\n","Epoch 00080: val_loss did not improve from 0.85581\n","Epoch 81/2000\n","34/34 [==============================] - 6s 175ms/step - loss: 0.8021 - accuracy: 0.9288 - val_loss: 0.8961 - val_accuracy: 0.7969\n","\n","Epoch 00081: val_loss did not improve from 0.85581\n","Epoch 00081: early stopping\n"]}],"source":["\n","save_best = tf.keras.callbacks.ModelCheckpoint(\n","    filepath=checkpoint_filepath, monitor='val_loss', verbose=1, save_best_only=True,\n","    save_weights_only=True, mode='auto', save_freq='epoch', options=None)\n","\n","early_stop = tf.keras.callbacks.EarlyStopping(\n","    monitor='val_loss',min_delta=0.0001,\n","    patience=20,verbose=1)\n","\n","history = model.fit_generator(\n","    generator=train_loader,\n","    validation_data=valid_loader,\n","    epochs=2000,\n","    callbacks=[save_best,early_stop,lr_scheduler],\n","    class_weight=class_weight_dict)\n",""]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1973: UserWarning: `Model.evaluate_generator` is deprecated and will be removed in a future version. Please use `Model.evaluate`, which supports generators.\n","  warnings.warn('`Model.evaluate_generator` is deprecated and '\n","1/1 [==============================] - 1s 1s/step - loss: 0.7386 - accuracy: 0.8368\n"]},{"output_type":"execute_result","data":{"text/plain":["[0.7385903000831604, 0.8367999792098999]"]},"metadata":{},"execution_count":6}],"source":["model.load_weights(checkpoint_filepath)\n","model.evaluate_generator(generator=test_loader,verbose=1)"]}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"codemirror_mode":{"name":"ipython","version":2},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython2","version":2},"orig_nbformat":4}}