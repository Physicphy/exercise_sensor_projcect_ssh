{"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import tensorflow as tf\n","import random as rn\n","from my_utils import Workout_dataset\n","from my_model import make_CNN_RNN_model\n","\n","import os\n","\n","os.environ['PYTHONHASHSEED'] = str(42)\n","\n","os.environ['TF_DETERMINISTIC_OPS'] = '1'\n","os.environ['TF_CUDNN_DETERMINISTIC'] = '1'\n","\n","tf.random.set_seed(42)\n","np.random.seed(42)\n","rn.seed(42)"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["train_dir = './data/train'\n","eval_dir = './data/train'\n","eval_label_dir = './data/data_y_train.csv'\n","label_dir = './data/data_y_train.csv'\n","\n","def scheduler(epoch, lr):\n","    if (epoch>20) and (lr > 0.00001):\n","        lr = lr*0.9\n","        return lr\n","    else:\n","        return lr\n","\n","train_y = pd.read_csv('./data/data_y_train.csv')  # label load\n","label_dict = dict()\n","for label, label_desc in zip(train_y.label, train_y.label_desc):\n","    label_dict[label] = label_desc\n","# 'Squat (kettlebell / goblet)'에서 [/]를 [,]으로 변경\n","label_dict[45] = 'Squat (kettlebell , goblet)'"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["lr_scheduler = tf.keras.callbacks.LearningRateScheduler(scheduler)\n","BATCH_SIZE = 64\n","\n","train_loader = Workout_dataset(\n","    train_dir, label_dir, mode='Train',\n","    fold=0, batch_size=BATCH_SIZE, augment=True, shuffle=True)\n","\n","valid_loader = Workout_dataset(\n","    train_dir, label_dir, mode='Valid',\n","    fold=0, batch_size=16, shuffle=True)\n",""]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["from sklearn.utils.class_weight import compute_class_weight\n","class_weights = compute_class_weight(\n","    'balanced',\n","    np.unique(train_y.label),\n","    train_y.label)\n","\n","class_weight_dict = dict(zip(\n","    list(range(61)),\n","    class_weights+1\n","    ))"]},{"cell_type":"code","execution_count":5,"metadata":{"tags":["outputPrepend"]},"outputs":[{"output_type":"stream","name":"stdout","text":["__________________________________________________________________________________\n","conv1d (Conv1D)                 (None, 300, 10)      910         concatenate[0][0]                \n","__________________________________________________________________________________________________\n","conv1d_2 (Conv1D)               (None, 300, 10)      910         concatenate_1[0][0]              \n","__________________________________________________________________________________________________\n","conv1d_6 (Conv1D)               (None, 300, 10)      730         concatenate_3[0][0]              \n","__________________________________________________________________________________________________\n","conv1d_8 (Conv1D)               (None, 300, 10)      1090        concatenate_4[0][0]              \n","__________________________________________________________________________________________________\n","conv1d_4 (Conv1D)               (None, 300, 10)      1090        concatenate_2[0][0]              \n","__________________________________________________________________________________________________\n","leaky_re_lu (LeakyReLU)         (None, 300, 10)      0           conv1d[0][0]                     \n","__________________________________________________________________________________________________\n","leaky_re_lu_4 (LeakyReLU)       (None, 300, 10)      0           conv1d_2[0][0]                   \n","__________________________________________________________________________________________________\n","leaky_re_lu_12 (LeakyReLU)      (None, 300, 10)      0           conv1d_6[0][0]                   \n","__________________________________________________________________________________________________\n","leaky_re_lu_16 (LeakyReLU)      (None, 300, 10)      0           conv1d_8[0][0]                   \n","__________________________________________________________________________________________________\n","leaky_re_lu_8 (LeakyReLU)       (None, 300, 10)      0           conv1d_4[0][0]                   \n","__________________________________________________________________________________________________\n","batch_normalization (BatchNorma (None, 300, 10)      40          leaky_re_lu[0][0]                \n","__________________________________________________________________________________________________\n","batch_normalization_4 (BatchNor (None, 300, 10)      40          leaky_re_lu_4[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_12 (BatchNo (None, 300, 10)      40          leaky_re_lu_12[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_16 (BatchNo (None, 300, 10)      40          leaky_re_lu_16[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_8 (BatchNor (None, 300, 10)      40          leaky_re_lu_8[0][0]              \n","__________________________________________________________________________________________________\n","gru (GRU)                       (None, 300, 20)      1920        batch_normalization[0][0]        \n","__________________________________________________________________________________________________\n","gru_2 (GRU)                     (None, 300, 20)      1920        batch_normalization_4[0][0]      \n","__________________________________________________________________________________________________\n","gru_6 (GRU)                     (None, 300, 20)      1920        batch_normalization_12[0][0]     \n","__________________________________________________________________________________________________\n","gru_8 (GRU)                     (None, 300, 20)      1920        batch_normalization_16[0][0]     \n","__________________________________________________________________________________________________\n","gru_4 (GRU)                     (None, 300, 20)      1920        batch_normalization_8[0][0]      \n","__________________________________________________________________________________________________\n","leaky_re_lu_1 (LeakyReLU)       (None, 300, 20)      0           gru[0][0]                        \n","__________________________________________________________________________________________________\n","leaky_re_lu_5 (LeakyReLU)       (None, 300, 20)      0           gru_2[0][0]                      \n","__________________________________________________________________________________________________\n","leaky_re_lu_13 (LeakyReLU)      (None, 300, 20)      0           gru_6[0][0]                      \n","__________________________________________________________________________________________________\n","leaky_re_lu_17 (LeakyReLU)      (None, 300, 20)      0           gru_8[0][0]                      \n","__________________________________________________________________________________________________\n","leaky_re_lu_9 (LeakyReLU)       (None, 300, 20)      0           gru_4[0][0]                      \n","__________________________________________________________________________________________________\n","batch_normalization_1 (BatchNor (None, 300, 20)      80          leaky_re_lu_1[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_5 (BatchNor (None, 300, 20)      80          leaky_re_lu_5[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_13 (BatchNo (None, 300, 20)      80          leaky_re_lu_13[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_17 (BatchNo (None, 300, 20)      80          leaky_re_lu_17[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_9 (BatchNor (None, 300, 20)      80          leaky_re_lu_9[0][0]              \n","__________________________________________________________________________________________________\n","conv1d_1 (Conv1D)               (None, 150, 60)      3660        batch_normalization_1[0][0]      \n","__________________________________________________________________________________________________\n","conv1d_3 (Conv1D)               (None, 150, 60)      3660        batch_normalization_5[0][0]      \n","__________________________________________________________________________________________________\n","conv1d_7 (Conv1D)               (None, 150, 60)      3660        batch_normalization_13[0][0]     \n","__________________________________________________________________________________________________\n","conv1d_9 (Conv1D)               (None, 150, 60)      3660        batch_normalization_17[0][0]     \n","__________________________________________________________________________________________________\n","conv1d_5 (Conv1D)               (None, 150, 60)      3660        batch_normalization_9[0][0]      \n","__________________________________________________________________________________________________\n","leaky_re_lu_2 (LeakyReLU)       (None, 150, 60)      0           conv1d_1[0][0]                   \n","__________________________________________________________________________________________________\n","leaky_re_lu_6 (LeakyReLU)       (None, 150, 60)      0           conv1d_3[0][0]                   \n","__________________________________________________________________________________________________\n","leaky_re_lu_14 (LeakyReLU)      (None, 150, 60)      0           conv1d_7[0][0]                   \n","__________________________________________________________________________________________________\n","leaky_re_lu_18 (LeakyReLU)      (None, 150, 60)      0           conv1d_9[0][0]                   \n","__________________________________________________________________________________________________\n","leaky_re_lu_10 (LeakyReLU)      (None, 150, 60)      0           conv1d_5[0][0]                   \n","__________________________________________________________________________________________________\n","batch_normalization_2 (BatchNor (None, 150, 60)      240         leaky_re_lu_2[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_6 (BatchNor (None, 150, 60)      240         leaky_re_lu_6[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_14 (BatchNo (None, 150, 60)      240         leaky_re_lu_14[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_18 (BatchNo (None, 150, 60)      240         leaky_re_lu_18[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_10 (BatchNo (None, 150, 60)      240         leaky_re_lu_10[0][0]             \n","__________________________________________________________________________________________________\n","gru_1 (GRU)                     (None, 150, 60)      21960       batch_normalization_2[0][0]      \n","__________________________________________________________________________________________________\n","gru_3 (GRU)                     (None, 150, 60)      21960       batch_normalization_6[0][0]      \n","__________________________________________________________________________________________________\n","gru_7 (GRU)                     (None, 150, 60)      21960       batch_normalization_14[0][0]     \n","__________________________________________________________________________________________________\n","gru_9 (GRU)                     (None, 150, 60)      21960       batch_normalization_18[0][0]     \n","__________________________________________________________________________________________________\n","gru_5 (GRU)                     (None, 150, 60)      21960       batch_normalization_10[0][0]     \n","__________________________________________________________________________________________________\n","leaky_re_lu_3 (LeakyReLU)       (None, 150, 60)      0           gru_1[0][0]                      \n","__________________________________________________________________________________________________\n","leaky_re_lu_7 (LeakyReLU)       (None, 150, 60)      0           gru_3[0][0]                      \n","__________________________________________________________________________________________________\n","leaky_re_lu_15 (LeakyReLU)      (None, 150, 60)      0           gru_7[0][0]                      \n","__________________________________________________________________________________________________\n","leaky_re_lu_19 (LeakyReLU)      (None, 150, 60)      0           gru_9[0][0]                      \n","__________________________________________________________________________________________________\n","leaky_re_lu_11 (LeakyReLU)      (None, 150, 60)      0           gru_5[0][0]                      \n","__________________________________________________________________________________________________\n","batch_normalization_3 (BatchNor (None, 150, 60)      240         leaky_re_lu_3[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_7 (BatchNor (None, 150, 60)      240         leaky_re_lu_7[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_15 (BatchNo (None, 150, 60)      240         leaky_re_lu_15[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_19 (BatchNo (None, 150, 60)      240         leaky_re_lu_19[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_11 (BatchNo (None, 150, 60)      240         leaky_re_lu_11[0][0]             \n","__________________________________________________________________________________________________\n","concatenate_5 (Concatenate)     (None, 150, 300)     0           batch_normalization_3[0][0]      \n","                                                                 batch_normalization_7[0][0]      \n","                                                                 batch_normalization_15[0][0]     \n","                                                                 batch_normalization_19[0][0]     \n","                                                                 batch_normalization_11[0][0]     \n","__________________________________________________________________________________________________\n","conv1d_11 (Conv1D)              (None, 150, 60)      162060      concatenate_5[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_20 (BatchNo (None, 150, 60)      240         conv1d_11[0][0]                  \n","__________________________________________________________________________________________________\n","leaky_re_lu_20 (LeakyReLU)      (None, 150, 60)      0           batch_normalization_20[0][0]     \n","__________________________________________________________________________________________________\n","conv1d_12 (Conv1D)              (None, 150, 120)     21720       leaky_re_lu_20[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_21 (BatchNo (None, 150, 120)     480         conv1d_12[0][0]                  \n","__________________________________________________________________________________________________\n","leaky_re_lu_21 (LeakyReLU)      (None, 150, 120)     0           batch_normalization_21[0][0]     \n","__________________________________________________________________________________________________\n","conv1d_13 (Conv1D)              (None, 150, 60)      21660       leaky_re_lu_21[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_22 (BatchNo (None, 150, 60)      240         conv1d_13[0][0]                  \n","__________________________________________________________________________________________________\n","leaky_re_lu_22 (LeakyReLU)      (None, 150, 60)      0           batch_normalization_22[0][0]     \n","__________________________________________________________________________________________________\n","conv1d_10 (Conv1D)              (None, 150, 60)      162060      concatenate_5[0][0]              \n","__________________________________________________________________________________________________\n","add (Add)                       (None, 150, 60)      0           leaky_re_lu_22[0][0]             \n","                                                                 conv1d_10[0][0]                  \n","__________________________________________________________________________________________________\n","conv1d_14 (Conv1D)              (None, 150, 60)      32460       add[0][0]                        \n","__________________________________________________________________________________________________\n","batch_normalization_23 (BatchNo (None, 150, 60)      240         conv1d_14[0][0]                  \n","__________________________________________________________________________________________________\n","leaky_re_lu_23 (LeakyReLU)      (None, 150, 60)      0           batch_normalization_23[0][0]     \n","__________________________________________________________________________________________________\n","conv1d_15 (Conv1D)              (None, 150, 120)     21720       leaky_re_lu_23[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_24 (BatchNo (None, 150, 120)     480         conv1d_15[0][0]                  \n","__________________________________________________________________________________________________\n","leaky_re_lu_24 (LeakyReLU)      (None, 150, 120)     0           batch_normalization_24[0][0]     \n","__________________________________________________________________________________________________\n","conv1d_16 (Conv1D)              (None, 150, 60)      21660       leaky_re_lu_24[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_25 (BatchNo (None, 150, 60)      240         conv1d_16[0][0]                  \n","__________________________________________________________________________________________________\n","leaky_re_lu_25 (LeakyReLU)      (None, 150, 60)      0           batch_normalization_25[0][0]     \n","__________________________________________________________________________________________________\n","add_1 (Add)                     (None, 150, 60)      0           leaky_re_lu_25[0][0]             \n","                                                                 add[0][0]                        \n","__________________________________________________________________________________________________\n","conv1d_17 (Conv1D)              (None, 150, 60)      32460       add_1[0][0]                      \n","__________________________________________________________________________________________________\n","batch_normalization_26 (BatchNo (None, 150, 60)      240         conv1d_17[0][0]                  \n","__________________________________________________________________________________________________\n","leaky_re_lu_26 (LeakyReLU)      (None, 150, 60)      0           batch_normalization_26[0][0]     \n","__________________________________________________________________________________________________\n","conv1d_18 (Conv1D)              (None, 150, 120)     21720       leaky_re_lu_26[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_27 (BatchNo (None, 150, 120)     480         conv1d_18[0][0]                  \n","__________________________________________________________________________________________________\n","leaky_re_lu_27 (LeakyReLU)      (None, 150, 120)     0           batch_normalization_27[0][0]     \n","__________________________________________________________________________________________________\n","conv1d_19 (Conv1D)              (None, 150, 60)      21660       leaky_re_lu_27[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_28 (BatchNo (None, 150, 60)      240         conv1d_19[0][0]                  \n","__________________________________________________________________________________________________\n","leaky_re_lu_28 (LeakyReLU)      (None, 150, 60)      0           batch_normalization_28[0][0]     \n","__________________________________________________________________________________________________\n","add_2 (Add)                     (None, 150, 60)      0           leaky_re_lu_28[0][0]             \n","                                                                 add_1[0][0]                      \n","__________________________________________________________________________________________________\n","batch_normalization_29 (BatchNo (None, 150, 60)      240         add_2[0][0]                      \n","__________________________________________________________________________________________________\n","global_average_pooling1d (Globa (None, 60)           0           batch_normalization_29[0][0]     \n","__________________________________________________________________________________________________\n","dense (Dense)                   (None, 61)           3721        global_average_pooling1d[0][0]   \n","==================================================================================================\n","Total params: 671,451\n","Trainable params: 668,391\n","Non-trainable params: 3,060\n","__________________________________________________________________________________________________\n","/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"]}],"source":["model = make_CNN_RNN_model(\n","    leakyrelu_alpha = 0.2,\n","    input_kernels = 10,\n","    input_kernel_width = 3,\n","    res_kernels = 60,\n","    res_kernel_width = 3,\n","    lr = 0.001,\n","    res_num = 3)\n","\n","model.summary()"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":["WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/array_ops.py:5049: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n","Instructions for updating:\n","The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n","/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1940: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n","  warnings.warn('`Model.fit_generator` is deprecated and '\n","Epoch 1/2000\n","34/34 [==============================] - 28s 240ms/step - loss: 224.3997 - accuracy: 0.3525 - val_loss: 145.6070 - val_accuracy: 0.4453\n","\n","Epoch 00001: val_loss improved from inf to 145.60704, saving model to ./save/cnn_gru_best.hdf5\n","Epoch 2/2000\n","34/34 [==============================] - 5s 152ms/step - loss: 107.7432 - accuracy: 0.5230 - val_loss: 73.6141 - val_accuracy: 0.4531\n","\n","Epoch 00002: val_loss improved from 145.60704 to 73.61409, saving model to ./save/cnn_gru_best.hdf5\n","Epoch 3/2000\n","34/34 [==============================] - 5s 151ms/step - loss: 56.4837 - accuracy: 0.6176 - val_loss: 39.8352 - val_accuracy: 0.4414\n","\n","Epoch 00003: val_loss improved from 73.61409 to 39.83523, saving model to ./save/cnn_gru_best.hdf5\n","Epoch 4/2000\n","34/34 [==============================] - 5s 153ms/step - loss: 31.3745 - accuracy: 0.6567 - val_loss: 22.6453 - val_accuracy: 0.4648\n","\n","Epoch 00004: val_loss improved from 39.83523 to 22.64531, saving model to ./save/cnn_gru_best.hdf5\n","Epoch 5/2000\n","34/34 [==============================] - 5s 152ms/step - loss: 18.6060 - accuracy: 0.6475 - val_loss: 13.9772 - val_accuracy: 0.4570\n","\n","Epoch 00005: val_loss improved from 22.64531 to 13.97723, saving model to ./save/cnn_gru_best.hdf5\n","Epoch 6/2000\n","34/34 [==============================] - 5s 152ms/step - loss: 11.7593 - accuracy: 0.6792 - val_loss: 9.5900 - val_accuracy: 0.4570\n","\n","Epoch 00006: val_loss improved from 13.97723 to 9.59002, saving model to ./save/cnn_gru_best.hdf5\n","Epoch 7/2000\n","34/34 [==============================] - 5s 151ms/step - loss: 7.9994 - accuracy: 0.6866 - val_loss: 7.3489 - val_accuracy: 0.4570\n","\n","Epoch 00007: val_loss improved from 9.59002 to 7.34885, saving model to ./save/cnn_gru_best.hdf5\n","Epoch 8/2000\n","34/34 [==============================] - 5s 156ms/step - loss: 6.1188 - accuracy: 0.7040 - val_loss: 6.1021 - val_accuracy: 0.4531\n","\n","Epoch 00008: val_loss improved from 7.34885 to 6.10211, saving model to ./save/cnn_gru_best.hdf5\n","Epoch 9/2000\n","34/34 [==============================] - 5s 153ms/step - loss: 5.0665 - accuracy: 0.6972 - val_loss: 5.5994 - val_accuracy: 0.4453\n","\n","Epoch 00009: val_loss improved from 6.10211 to 5.59938, saving model to ./save/cnn_gru_best.hdf5\n","Epoch 10/2000\n","34/34 [==============================] - 5s 154ms/step - loss: 4.4726 - accuracy: 0.7073 - val_loss: 6.1301 - val_accuracy: 0.0234\n","\n","Epoch 00010: val_loss did not improve from 5.59938\n","Epoch 11/2000\n","34/34 [==============================] - 5s 154ms/step - loss: 3.9364 - accuracy: 0.7339 - val_loss: 6.5966 - val_accuracy: 0.0117\n","\n","Epoch 00011: val_loss did not improve from 5.59938\n","Epoch 12/2000\n","34/34 [==============================] - 5s 154ms/step - loss: 3.5968 - accuracy: 0.7403 - val_loss: 6.6671 - val_accuracy: 0.0156\n","\n","Epoch 00012: val_loss did not improve from 5.59938\n","Epoch 13/2000\n","34/34 [==============================] - 5s 151ms/step - loss: 3.5465 - accuracy: 0.7275 - val_loss: 5.4728 - val_accuracy: 0.0977\n","\n","Epoch 00013: val_loss improved from 5.59938 to 5.47279, saving model to ./save/cnn_gru_best.hdf5\n","Epoch 14/2000\n","34/34 [==============================] - 5s 151ms/step - loss: 3.3452 - accuracy: 0.7486 - val_loss: 5.9894 - val_accuracy: 0.0898\n","\n","Epoch 00014: val_loss did not improve from 5.47279\n","Epoch 15/2000\n","34/34 [==============================] - 5s 152ms/step - loss: 3.1697 - accuracy: 0.7684 - val_loss: 5.0546 - val_accuracy: 0.1836\n","\n","Epoch 00015: val_loss improved from 5.47279 to 5.05462, saving model to ./save/cnn_gru_best.hdf5\n","Epoch 16/2000\n","34/34 [==============================] - 5s 152ms/step - loss: 3.1609 - accuracy: 0.7707 - val_loss: 4.6118 - val_accuracy: 0.3359\n","\n","Epoch 00016: val_loss improved from 5.05462 to 4.61176, saving model to ./save/cnn_gru_best.hdf5\n","Epoch 17/2000\n","34/34 [==============================] - 5s 152ms/step - loss: 3.1667 - accuracy: 0.7477 - val_loss: 4.1771 - val_accuracy: 0.2891\n","\n","Epoch 00017: val_loss improved from 4.61176 to 4.17708, saving model to ./save/cnn_gru_best.hdf5\n","Epoch 18/2000\n","34/34 [==============================] - 5s 154ms/step - loss: 2.9146 - accuracy: 0.7831 - val_loss: 2.8144 - val_accuracy: 0.5117\n","\n","Epoch 00018: val_loss improved from 4.17708 to 2.81441, saving model to ./save/cnn_gru_best.hdf5\n","Epoch 19/2000\n","34/34 [==============================] - 5s 152ms/step - loss: 3.0437 - accuracy: 0.7647 - val_loss: 2.4288 - val_accuracy: 0.5938\n","\n","Epoch 00019: val_loss improved from 2.81441 to 2.42878, saving model to ./save/cnn_gru_best.hdf5\n","Epoch 20/2000\n","34/34 [==============================] - 5s 155ms/step - loss: 2.8816 - accuracy: 0.7748 - val_loss: 2.7460 - val_accuracy: 0.5820\n","\n","Epoch 00020: val_loss did not improve from 2.42878\n","Epoch 21/2000\n","34/34 [==============================] - 5s 154ms/step - loss: 3.0013 - accuracy: 0.7688 - val_loss: 2.4039 - val_accuracy: 0.6016\n","\n","Epoch 00021: val_loss improved from 2.42878 to 2.40391, saving model to ./save/cnn_gru_best.hdf5\n","Epoch 22/2000\n","34/34 [==============================] - 5s 151ms/step - loss: 2.6417 - accuracy: 0.7996 - val_loss: 2.1131 - val_accuracy: 0.6367\n","\n","Epoch 00022: val_loss improved from 2.40391 to 2.11307, saving model to ./save/cnn_gru_best.hdf5\n","Epoch 23/2000\n","34/34 [==============================] - 5s 153ms/step - loss: 2.4825 - accuracy: 0.8153 - val_loss: 2.5611 - val_accuracy: 0.5703\n","\n","Epoch 00023: val_loss did not improve from 2.11307\n","Epoch 24/2000\n","34/34 [==============================] - 5s 154ms/step - loss: 2.3550 - accuracy: 0.8189 - val_loss: 1.9025 - val_accuracy: 0.6484\n","\n","Epoch 00024: val_loss improved from 2.11307 to 1.90248, saving model to ./save/cnn_gru_best.hdf5\n","Epoch 25/2000\n","34/34 [==============================] - 5s 151ms/step - loss: 2.2325 - accuracy: 0.8254 - val_loss: 2.3690 - val_accuracy: 0.5820\n","\n","Epoch 00025: val_loss did not improve from 1.90248\n","Epoch 26/2000\n","34/34 [==============================] - 5s 152ms/step - loss: 2.0782 - accuracy: 0.8405 - val_loss: 1.5526 - val_accuracy: 0.7148\n","\n","Epoch 00026: val_loss improved from 1.90248 to 1.55265, saving model to ./save/cnn_gru_best.hdf5\n","Epoch 27/2000\n","34/34 [==============================] - 5s 153ms/step - loss: 2.0483 - accuracy: 0.8189 - val_loss: 1.7833 - val_accuracy: 0.6680\n","\n","Epoch 00027: val_loss did not improve from 1.55265\n","Epoch 28/2000\n","34/34 [==============================] - 5s 154ms/step - loss: 1.9994 - accuracy: 0.8465 - val_loss: 1.5330 - val_accuracy: 0.7148\n","\n","Epoch 00028: val_loss improved from 1.55265 to 1.53300, saving model to ./save/cnn_gru_best.hdf5\n","Epoch 29/2000\n","34/34 [==============================] - 5s 150ms/step - loss: 1.8697 - accuracy: 0.8465 - val_loss: 1.4228 - val_accuracy: 0.7344\n","\n","Epoch 00029: val_loss improved from 1.53300 to 1.42276, saving model to ./save/cnn_gru_best.hdf5\n","Epoch 30/2000\n","34/34 [==============================] - 5s 157ms/step - loss: 1.8328 - accuracy: 0.8562 - val_loss: 1.3355 - val_accuracy: 0.7344\n","\n","Epoch 00030: val_loss improved from 1.42276 to 1.33545, saving model to ./save/cnn_gru_best.hdf5\n","Epoch 31/2000\n","34/34 [==============================] - 5s 152ms/step - loss: 1.7592 - accuracy: 0.8479 - val_loss: 1.4561 - val_accuracy: 0.7031\n","\n","Epoch 00031: val_loss did not improve from 1.33545\n","Epoch 32/2000\n","34/34 [==============================] - 5s 155ms/step - loss: 1.7575 - accuracy: 0.8575 - val_loss: 1.3415 - val_accuracy: 0.7031\n","\n","Epoch 00032: val_loss did not improve from 1.33545\n","Epoch 33/2000\n","34/34 [==============================] - 5s 155ms/step - loss: 1.7421 - accuracy: 0.8479 - val_loss: 1.5862 - val_accuracy: 0.6719\n","\n","Epoch 00033: val_loss did not improve from 1.33545\n","Epoch 34/2000\n","34/34 [==============================] - 5s 153ms/step - loss: 1.6009 - accuracy: 0.8686 - val_loss: 1.5336 - val_accuracy: 0.6484\n","\n","Epoch 00034: val_loss did not improve from 1.33545\n","Epoch 35/2000\n","34/34 [==============================] - 5s 155ms/step - loss: 1.4231 - accuracy: 0.8787 - val_loss: 1.2941 - val_accuracy: 0.7188\n","\n","Epoch 00035: val_loss improved from 1.33545 to 1.29415, saving model to ./save/cnn_gru_best.hdf5\n","Epoch 36/2000\n","34/34 [==============================] - 5s 151ms/step - loss: 1.3846 - accuracy: 0.8869 - val_loss: 1.1581 - val_accuracy: 0.7383\n","\n","Epoch 00036: val_loss improved from 1.29415 to 1.15812, saving model to ./save/cnn_gru_best.hdf5\n","Epoch 37/2000\n","34/34 [==============================] - 5s 151ms/step - loss: 1.3174 - accuracy: 0.8934 - val_loss: 1.1695 - val_accuracy: 0.7344\n","\n","Epoch 00037: val_loss did not improve from 1.15812\n","Epoch 38/2000\n","34/34 [==============================] - 5s 152ms/step - loss: 1.5553 - accuracy: 0.8585 - val_loss: 1.1192 - val_accuracy: 0.7617\n","\n","Epoch 00038: val_loss improved from 1.15812 to 1.11916, saving model to ./save/cnn_gru_best.hdf5\n","Epoch 39/2000\n","34/34 [==============================] - 5s 154ms/step - loss: 1.2830 - accuracy: 0.8938 - val_loss: 1.0720 - val_accuracy: 0.7656\n","\n","Epoch 00039: val_loss improved from 1.11916 to 1.07198, saving model to ./save/cnn_gru_best.hdf5\n","Epoch 40/2000\n","34/34 [==============================] - 6s 164ms/step - loss: 1.2848 - accuracy: 0.8957 - val_loss: 1.1655 - val_accuracy: 0.7344\n","\n","Epoch 00040: val_loss did not improve from 1.07198\n","Epoch 41/2000\n","34/34 [==============================] - 5s 157ms/step - loss: 1.3587 - accuracy: 0.8837 - val_loss: 1.1976 - val_accuracy: 0.7383\n","\n","Epoch 00041: val_loss did not improve from 1.07198\n","Epoch 42/2000\n","34/34 [==============================] - 6s 160ms/step - loss: 1.2292 - accuracy: 0.9035 - val_loss: 1.0855 - val_accuracy: 0.7383\n","\n","Epoch 00042: val_loss did not improve from 1.07198\n","Epoch 43/2000\n","34/34 [==============================] - 5s 158ms/step - loss: 1.0914 - accuracy: 0.9122 - val_loss: 0.9627 - val_accuracy: 0.7695\n","\n","Epoch 00043: val_loss improved from 1.07198 to 0.96275, saving model to ./save/cnn_gru_best.hdf5\n","Epoch 44/2000\n","34/34 [==============================] - 6s 166ms/step - loss: 1.1839 - accuracy: 0.9035 - val_loss: 1.1153 - val_accuracy: 0.7266\n","\n","Epoch 00044: val_loss did not improve from 0.96275\n","Epoch 45/2000\n","34/34 [==============================] - 6s 161ms/step - loss: 1.1646 - accuracy: 0.9035 - val_loss: 1.0066 - val_accuracy: 0.7734\n","\n","Epoch 00045: val_loss did not improve from 0.96275\n","Epoch 46/2000\n","34/34 [==============================] - 5s 158ms/step - loss: 1.0861 - accuracy: 0.9191 - val_loss: 1.0233 - val_accuracy: 0.7578\n","\n","Epoch 00046: val_loss did not improve from 0.96275\n","Epoch 47/2000\n","34/34 [==============================] - 5s 156ms/step - loss: 1.1649 - accuracy: 0.9012 - val_loss: 0.9757 - val_accuracy: 0.7461\n","\n","Epoch 00047: val_loss did not improve from 0.96275\n","Epoch 48/2000\n","34/34 [==============================] - 5s 158ms/step - loss: 1.1481 - accuracy: 0.9026 - val_loss: 1.0163 - val_accuracy: 0.7812\n","\n","Epoch 00048: val_loss did not improve from 0.96275\n","Epoch 49/2000\n","34/34 [==============================] - 5s 155ms/step - loss: 1.0716 - accuracy: 0.9072 - val_loss: 1.0034 - val_accuracy: 0.7852\n","\n","Epoch 00049: val_loss did not improve from 0.96275\n","Epoch 50/2000\n","34/34 [==============================] - 5s 157ms/step - loss: 1.0175 - accuracy: 0.9196 - val_loss: 0.9835 - val_accuracy: 0.7812\n","\n","Epoch 00050: val_loss did not improve from 0.96275\n","Epoch 51/2000\n","34/34 [==============================] - 5s 158ms/step - loss: 1.0568 - accuracy: 0.9127 - val_loss: 1.0126 - val_accuracy: 0.7734\n","\n","Epoch 00051: val_loss did not improve from 0.96275\n","Epoch 52/2000\n","34/34 [==============================] - 5s 157ms/step - loss: 1.0540 - accuracy: 0.9104 - val_loss: 0.9943 - val_accuracy: 0.7461\n","\n","Epoch 00052: val_loss did not improve from 0.96275\n","Epoch 53/2000\n","34/34 [==============================] - 5s 155ms/step - loss: 0.9428 - accuracy: 0.9200 - val_loss: 0.9551 - val_accuracy: 0.7695\n","\n","Epoch 00053: val_loss improved from 0.96275 to 0.95514, saving model to ./save/cnn_gru_best.hdf5\n","Epoch 54/2000\n","34/34 [==============================] - 5s 155ms/step - loss: 1.0186 - accuracy: 0.9104 - val_loss: 0.9522 - val_accuracy: 0.7617\n","\n","Epoch 00054: val_loss improved from 0.95514 to 0.95224, saving model to ./save/cnn_gru_best.hdf5\n","Epoch 55/2000\n","34/34 [==============================] - 5s 157ms/step - loss: 1.0781 - accuracy: 0.9076 - val_loss: 1.0045 - val_accuracy: 0.7422\n","\n","Epoch 00055: val_loss did not improve from 0.95224\n","Epoch 56/2000\n","34/34 [==============================] - 5s 155ms/step - loss: 1.0162 - accuracy: 0.9113 - val_loss: 0.9580 - val_accuracy: 0.7773\n","\n","Epoch 00056: val_loss did not improve from 0.95224\n","Epoch 57/2000\n","34/34 [==============================] - 5s 155ms/step - loss: 0.9589 - accuracy: 0.9159 - val_loss: 0.9533 - val_accuracy: 0.7734\n","\n","Epoch 00057: val_loss did not improve from 0.95224\n","Epoch 58/2000\n","34/34 [==============================] - 5s 155ms/step - loss: 0.8978 - accuracy: 0.9320 - val_loss: 0.9630 - val_accuracy: 0.7500\n","\n","Epoch 00058: val_loss did not improve from 0.95224\n","Epoch 59/2000\n","34/34 [==============================] - 5s 153ms/step - loss: 0.8684 - accuracy: 0.9320 - val_loss: 0.9178 - val_accuracy: 0.7695\n","\n","Epoch 00059: val_loss improved from 0.95224 to 0.91777, saving model to ./save/cnn_gru_best.hdf5\n","Epoch 60/2000\n","34/34 [==============================] - 5s 152ms/step - loss: 0.8573 - accuracy: 0.9301 - val_loss: 0.9504 - val_accuracy: 0.7812\n","\n","Epoch 00060: val_loss did not improve from 0.91777\n","Epoch 61/2000\n","34/34 [==============================] - 5s 155ms/step - loss: 0.7834 - accuracy: 0.9380 - val_loss: 0.8781 - val_accuracy: 0.7578\n","\n","Epoch 00061: val_loss improved from 0.91777 to 0.87809, saving model to ./save/cnn_gru_best.hdf5\n","Epoch 62/2000\n","34/34 [==============================] - 5s 155ms/step - loss: 0.8354 - accuracy: 0.9301 - val_loss: 0.9679 - val_accuracy: 0.7656\n","\n","Epoch 00062: val_loss did not improve from 0.87809\n","Epoch 63/2000\n","34/34 [==============================] - 5s 152ms/step - loss: 0.8057 - accuracy: 0.9357 - val_loss: 0.9283 - val_accuracy: 0.7734\n","\n","Epoch 00063: val_loss did not improve from 0.87809\n","Epoch 64/2000\n","34/34 [==============================] - 5s 155ms/step - loss: 0.8202 - accuracy: 0.9343 - val_loss: 0.9246 - val_accuracy: 0.7891\n","\n","Epoch 00064: val_loss did not improve from 0.87809\n","Epoch 65/2000\n","34/34 [==============================] - 5s 154ms/step - loss: 0.8824 - accuracy: 0.9265 - val_loss: 0.9410 - val_accuracy: 0.7656\n","\n","Epoch 00065: val_loss did not improve from 0.87809\n","Epoch 66/2000\n","34/34 [==============================] - 5s 155ms/step - loss: 0.8652 - accuracy: 0.9343 - val_loss: 0.9486 - val_accuracy: 0.7773\n","\n","Epoch 00066: val_loss did not improve from 0.87809\n","Epoch 67/2000\n","34/34 [==============================] - 5s 152ms/step - loss: 0.7827 - accuracy: 0.9398 - val_loss: 0.9300 - val_accuracy: 0.7656\n","\n","Epoch 00067: val_loss did not improve from 0.87809\n","Epoch 68/2000\n","34/34 [==============================] - 5s 153ms/step - loss: 0.8929 - accuracy: 0.9288 - val_loss: 0.9188 - val_accuracy: 0.7812\n","\n","Epoch 00068: val_loss did not improve from 0.87809\n","Epoch 69/2000\n","34/34 [==============================] - 5s 153ms/step - loss: 0.9333 - accuracy: 0.9136 - val_loss: 0.9195 - val_accuracy: 0.7656\n","\n","Epoch 00069: val_loss did not improve from 0.87809\n","Epoch 70/2000\n","34/34 [==============================] - 5s 154ms/step - loss: 0.8857 - accuracy: 0.9237 - val_loss: 0.9252 - val_accuracy: 0.7773\n","\n","Epoch 00070: val_loss did not improve from 0.87809\n","Epoch 71/2000\n","34/34 [==============================] - 5s 153ms/step - loss: 0.8459 - accuracy: 0.9283 - val_loss: 0.9674 - val_accuracy: 0.7617\n","\n","Epoch 00071: val_loss did not improve from 0.87809\n","Epoch 72/2000\n","34/34 [==============================] - 6s 164ms/step - loss: 0.7577 - accuracy: 0.9389 - val_loss: 0.9062 - val_accuracy: 0.7734\n","\n","Epoch 00072: val_loss did not improve from 0.87809\n","Epoch 73/2000\n","34/34 [==============================] - 6s 170ms/step - loss: 0.7341 - accuracy: 0.9435 - val_loss: 0.9415 - val_accuracy: 0.7773\n","\n","Epoch 00073: val_loss did not improve from 0.87809\n","Epoch 74/2000\n","34/34 [==============================] - 5s 155ms/step - loss: 0.8089 - accuracy: 0.9242 - val_loss: 0.9399 - val_accuracy: 0.7656\n","\n","Epoch 00074: val_loss did not improve from 0.87809\n","Epoch 75/2000\n","34/34 [==============================] - 5s 154ms/step - loss: 0.9041 - accuracy: 0.9196 - val_loss: 0.9495 - val_accuracy: 0.7695\n","\n","Epoch 00075: val_loss did not improve from 0.87809\n","Epoch 76/2000\n","34/34 [==============================] - 5s 154ms/step - loss: 0.8025 - accuracy: 0.9366 - val_loss: 0.9206 - val_accuracy: 0.7695\n","\n","Epoch 00076: val_loss did not improve from 0.87809\n","Epoch 77/2000\n","34/34 [==============================] - 5s 155ms/step - loss: 0.8266 - accuracy: 0.9315 - val_loss: 0.9730 - val_accuracy: 0.7539\n","\n","Epoch 00077: val_loss did not improve from 0.87809\n","Epoch 78/2000\n","34/34 [==============================] - 5s 151ms/step - loss: 0.8832 - accuracy: 0.9311 - val_loss: 0.9093 - val_accuracy: 0.7656\n","\n","Epoch 00078: val_loss did not improve from 0.87809\n","Epoch 79/2000\n","34/34 [==============================] - 5s 153ms/step - loss: 0.7931 - accuracy: 0.9306 - val_loss: 0.9272 - val_accuracy: 0.7656\n","\n","Epoch 00079: val_loss did not improve from 0.87809\n","Epoch 80/2000\n","34/34 [==============================] - 5s 153ms/step - loss: 0.8124 - accuracy: 0.9329 - val_loss: 0.9353 - val_accuracy: 0.7734\n","\n","Epoch 00080: val_loss did not improve from 0.87809\n","Epoch 81/2000\n","34/34 [==============================] - 5s 152ms/step - loss: 0.8249 - accuracy: 0.9297 - val_loss: 0.9344 - val_accuracy: 0.7539\n","\n","Epoch 00081: val_loss did not improve from 0.87809\n","Epoch 00081: early stopping\n"]}],"source":["checkpoint_filepath = \"./save/cnn_gru_best.hdf5\"\n","\n","save_best = tf.keras.callbacks.ModelCheckpoint(\n","    filepath=checkpoint_filepath, monitor='val_loss', verbose=1, save_best_only=True,\n","    save_weights_only=True, mode='auto', save_freq='epoch', options=None)\n","\n","early_stop = tf.keras.callbacks.EarlyStopping(\n","    monitor='val_loss',min_delta=0.0001,\n","    patience=20,verbose=1)\n","\n","history = model.fit_generator(\n","    generator=train_loader,\n","    validation_data=valid_loader,\n","    epochs=2000,\n","    callbacks=[save_best,early_stop,lr_scheduler],\n","    class_weight=class_weight_dict)"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["test_dir = './data/test'\n","test_label_dir = './data/data_y_test.csv'"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["test_loader = Workout_dataset(\n","        test_dir, test_label_dir, mode='Test', batch_size=625, shuffle=False)"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1973: UserWarning: `Model.evaluate_generator` is deprecated and will be removed in a future version. Please use `Model.evaluate`, which supports generators.\n","  warnings.warn('`Model.evaluate_generator` is deprecated and '\n","1/1 [==============================] - 1s 990ms/step - loss: 0.7637 - accuracy: 0.8192\n"]},{"output_type":"execute_result","data":{"text/plain":["[0.7636738419532776, 0.8191999793052673]"]},"metadata":{},"execution_count":10}],"source":["model.load_weights(checkpoint_filepath)\n","model.evaluate_generator(generator=test_loader,verbose=1)"]}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"codemirror_mode":{"name":"ipython","version":2},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython2","version":2},"orig_nbformat":4}}