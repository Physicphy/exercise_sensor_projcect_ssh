{"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import tensorflow as tf\n","import random as rn\n","from my_utils import Workout_dataset, class_weight_dict\n","from my_model import make_CNN_RNN_model\n","\n","import os"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["# seed 고정\n","os.environ['PYTHONHASHSEED'] = str(42)\n","\n","os.environ['TF_DETERMINISTIC_OPS'] = '1'\n","os.environ['TF_CUDNN_DETERMINISTIC'] = '1'\n","\n","tf.random.set_seed(42)\n","np.random.seed(42)\n","rn.seed(42)"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["def scheduler(epoch, lr):\n","    if (epoch>20) and (lr > 0.00001):\n","        lr = lr*0.9\n","        return lr\n","    else:\n","        return lr\n","\n","lr_scheduler = tf.keras.callbacks.LearningRateScheduler(scheduler)\n","\n","train_dir = './data/train'\n","label_dir = './data/data_y_train.csv'\n","test_dir = './data/test'\n","test_label_dir = './data/data_y_test.csv'\n","checkpoint_filepath = \"./save/cnn_gru_best.hdf5\"\n","\n","BATCH_SIZE = 64\n","\n","train_loader = Workout_dataset(\n","    train_dir, label_dir, mode='Train',\n","    fold=0, batch_size=BATCH_SIZE, augment=True, shuffle=True)\n","\n","valid_loader = Workout_dataset(\n","    train_dir, label_dir, mode='Valid',\n","    fold=0, batch_size=16, shuffle=True)\n","\n","test_loader = Workout_dataset(\n","    test_dir, test_label_dir, mode='Test',\n","    batch_size=625, shuffle=False)\n",""]},{"cell_type":"code","execution_count":4,"metadata":{"tags":["outputPrepend"]},"outputs":[{"output_type":"stream","name":"stdout","text":["__________________________________________________________________________________\n","batch_normalization_14 (BatchNo (None, 150, 60)      240         leaky_re_lu_14[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_18 (BatchNo (None, 150, 60)      240         leaky_re_lu_18[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_10 (BatchNo (None, 150, 60)      240         leaky_re_lu_10[0][0]             \n","__________________________________________________________________________________________________\n","gru_1 (GRU)                     (None, 150, 60)      21960       batch_normalization_2[0][0]      \n","__________________________________________________________________________________________________\n","gru_3 (GRU)                     (None, 150, 60)      21960       batch_normalization_6[0][0]      \n","__________________________________________________________________________________________________\n","gru_7 (GRU)                     (None, 150, 60)      21960       batch_normalization_14[0][0]     \n","__________________________________________________________________________________________________\n","gru_9 (GRU)                     (None, 150, 60)      21960       batch_normalization_18[0][0]     \n","__________________________________________________________________________________________________\n","gru_5 (GRU)                     (None, 150, 60)      21960       batch_normalization_10[0][0]     \n","__________________________________________________________________________________________________\n","leaky_re_lu_3 (LeakyReLU)       (None, 150, 60)      0           gru_1[0][0]                      \n","__________________________________________________________________________________________________\n","leaky_re_lu_7 (LeakyReLU)       (None, 150, 60)      0           gru_3[0][0]                      \n","__________________________________________________________________________________________________\n","leaky_re_lu_15 (LeakyReLU)      (None, 150, 60)      0           gru_7[0][0]                      \n","__________________________________________________________________________________________________\n","leaky_re_lu_19 (LeakyReLU)      (None, 150, 60)      0           gru_9[0][0]                      \n","__________________________________________________________________________________________________\n","leaky_re_lu_11 (LeakyReLU)      (None, 150, 60)      0           gru_5[0][0]                      \n","__________________________________________________________________________________________________\n","batch_normalization_3 (BatchNor (None, 150, 60)      240         leaky_re_lu_3[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_7 (BatchNor (None, 150, 60)      240         leaky_re_lu_7[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_15 (BatchNo (None, 150, 60)      240         leaky_re_lu_15[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_19 (BatchNo (None, 150, 60)      240         leaky_re_lu_19[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_11 (BatchNo (None, 150, 60)      240         leaky_re_lu_11[0][0]             \n","__________________________________________________________________________________________________\n","concatenate_5 (Concatenate)     (None, 150, 300)     0           batch_normalization_3[0][0]      \n","                                                                 batch_normalization_7[0][0]      \n","                                                                 batch_normalization_15[0][0]     \n","                                                                 batch_normalization_19[0][0]     \n","                                                                 batch_normalization_11[0][0]     \n","__________________________________________________________________________________________________\n","conv1d_11 (Conv1D)              (None, 150, 60)      162060      concatenate_5[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_20 (BatchNo (None, 150, 60)      240         conv1d_11[0][0]                  \n","__________________________________________________________________________________________________\n","leaky_re_lu_20 (LeakyReLU)      (None, 150, 60)      0           batch_normalization_20[0][0]     \n","__________________________________________________________________________________________________\n","conv1d_12 (Conv1D)              (None, 150, 120)     21720       leaky_re_lu_20[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_21 (BatchNo (None, 150, 120)     480         conv1d_12[0][0]                  \n","__________________________________________________________________________________________________\n","leaky_re_lu_21 (LeakyReLU)      (None, 150, 120)     0           batch_normalization_21[0][0]     \n","__________________________________________________________________________________________________\n","conv1d_13 (Conv1D)              (None, 150, 60)      21660       leaky_re_lu_21[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_22 (BatchNo (None, 150, 60)      240         conv1d_13[0][0]                  \n","__________________________________________________________________________________________________\n","leaky_re_lu_22 (LeakyReLU)      (None, 150, 60)      0           batch_normalization_22[0][0]     \n","__________________________________________________________________________________________________\n","conv1d_10 (Conv1D)              (None, 150, 60)      162060      concatenate_5[0][0]              \n","__________________________________________________________________________________________________\n","add (Add)                       (None, 150, 60)      0           leaky_re_lu_22[0][0]             \n","                                                                 conv1d_10[0][0]                  \n","__________________________________________________________________________________________________\n","conv1d_14 (Conv1D)              (None, 150, 60)      32460       add[0][0]                        \n","__________________________________________________________________________________________________\n","batch_normalization_23 (BatchNo (None, 150, 60)      240         conv1d_14[0][0]                  \n","__________________________________________________________________________________________________\n","leaky_re_lu_23 (LeakyReLU)      (None, 150, 60)      0           batch_normalization_23[0][0]     \n","__________________________________________________________________________________________________\n","conv1d_15 (Conv1D)              (None, 150, 120)     21720       leaky_re_lu_23[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_24 (BatchNo (None, 150, 120)     480         conv1d_15[0][0]                  \n","__________________________________________________________________________________________________\n","leaky_re_lu_24 (LeakyReLU)      (None, 150, 120)     0           batch_normalization_24[0][0]     \n","__________________________________________________________________________________________________\n","conv1d_16 (Conv1D)              (None, 150, 60)      21660       leaky_re_lu_24[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_25 (BatchNo (None, 150, 60)      240         conv1d_16[0][0]                  \n","__________________________________________________________________________________________________\n","leaky_re_lu_25 (LeakyReLU)      (None, 150, 60)      0           batch_normalization_25[0][0]     \n","__________________________________________________________________________________________________\n","add_1 (Add)                     (None, 150, 60)      0           leaky_re_lu_25[0][0]             \n","                                                                 add[0][0]                        \n","__________________________________________________________________________________________________\n","conv1d_17 (Conv1D)              (None, 150, 60)      32460       add_1[0][0]                      \n","__________________________________________________________________________________________________\n","batch_normalization_26 (BatchNo (None, 150, 60)      240         conv1d_17[0][0]                  \n","__________________________________________________________________________________________________\n","leaky_re_lu_26 (LeakyReLU)      (None, 150, 60)      0           batch_normalization_26[0][0]     \n","__________________________________________________________________________________________________\n","conv1d_18 (Conv1D)              (None, 150, 120)     21720       leaky_re_lu_26[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_27 (BatchNo (None, 150, 120)     480         conv1d_18[0][0]                  \n","__________________________________________________________________________________________________\n","leaky_re_lu_27 (LeakyReLU)      (None, 150, 120)     0           batch_normalization_27[0][0]     \n","__________________________________________________________________________________________________\n","conv1d_19 (Conv1D)              (None, 150, 60)      21660       leaky_re_lu_27[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_28 (BatchNo (None, 150, 60)      240         conv1d_19[0][0]                  \n","__________________________________________________________________________________________________\n","leaky_re_lu_28 (LeakyReLU)      (None, 150, 60)      0           batch_normalization_28[0][0]     \n","__________________________________________________________________________________________________\n","add_2 (Add)                     (None, 150, 60)      0           leaky_re_lu_28[0][0]             \n","                                                                 add_1[0][0]                      \n","__________________________________________________________________________________________________\n","conv1d_20 (Conv1D)              (None, 150, 60)      32460       add_2[0][0]                      \n","__________________________________________________________________________________________________\n","batch_normalization_29 (BatchNo (None, 150, 60)      240         conv1d_20[0][0]                  \n","__________________________________________________________________________________________________\n","leaky_re_lu_29 (LeakyReLU)      (None, 150, 60)      0           batch_normalization_29[0][0]     \n","__________________________________________________________________________________________________\n","conv1d_21 (Conv1D)              (None, 150, 120)     21720       leaky_re_lu_29[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_30 (BatchNo (None, 150, 120)     480         conv1d_21[0][0]                  \n","__________________________________________________________________________________________________\n","leaky_re_lu_30 (LeakyReLU)      (None, 150, 120)     0           batch_normalization_30[0][0]     \n","__________________________________________________________________________________________________\n","conv1d_22 (Conv1D)              (None, 150, 60)      21660       leaky_re_lu_30[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_31 (BatchNo (None, 150, 60)      240         conv1d_22[0][0]                  \n","__________________________________________________________________________________________________\n","leaky_re_lu_31 (LeakyReLU)      (None, 150, 60)      0           batch_normalization_31[0][0]     \n","__________________________________________________________________________________________________\n","add_3 (Add)                     (None, 150, 60)      0           leaky_re_lu_31[0][0]             \n","                                                                 add_2[0][0]                      \n","__________________________________________________________________________________________________\n","conv1d_23 (Conv1D)              (None, 150, 60)      32460       add_3[0][0]                      \n","__________________________________________________________________________________________________\n","batch_normalization_32 (BatchNo (None, 150, 60)      240         conv1d_23[0][0]                  \n","__________________________________________________________________________________________________\n","leaky_re_lu_32 (LeakyReLU)      (None, 150, 60)      0           batch_normalization_32[0][0]     \n","__________________________________________________________________________________________________\n","conv1d_24 (Conv1D)              (None, 150, 120)     21720       leaky_re_lu_32[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_33 (BatchNo (None, 150, 120)     480         conv1d_24[0][0]                  \n","__________________________________________________________________________________________________\n","leaky_re_lu_33 (LeakyReLU)      (None, 150, 120)     0           batch_normalization_33[0][0]     \n","__________________________________________________________________________________________________\n","conv1d_25 (Conv1D)              (None, 150, 60)      21660       leaky_re_lu_33[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_34 (BatchNo (None, 150, 60)      240         conv1d_25[0][0]                  \n","__________________________________________________________________________________________________\n","leaky_re_lu_34 (LeakyReLU)      (None, 150, 60)      0           batch_normalization_34[0][0]     \n","__________________________________________________________________________________________________\n","add_4 (Add)                     (None, 150, 60)      0           leaky_re_lu_34[0][0]             \n","                                                                 add_3[0][0]                      \n","__________________________________________________________________________________________________\n","conv1d_26 (Conv1D)              (None, 150, 60)      32460       add_4[0][0]                      \n","__________________________________________________________________________________________________\n","batch_normalization_35 (BatchNo (None, 150, 60)      240         conv1d_26[0][0]                  \n","__________________________________________________________________________________________________\n","leaky_re_lu_35 (LeakyReLU)      (None, 150, 60)      0           batch_normalization_35[0][0]     \n","__________________________________________________________________________________________________\n","conv1d_27 (Conv1D)              (None, 150, 120)     21720       leaky_re_lu_35[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_36 (BatchNo (None, 150, 120)     480         conv1d_27[0][0]                  \n","__________________________________________________________________________________________________\n","leaky_re_lu_36 (LeakyReLU)      (None, 150, 120)     0           batch_normalization_36[0][0]     \n","__________________________________________________________________________________________________\n","conv1d_28 (Conv1D)              (None, 150, 60)      21660       leaky_re_lu_36[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_37 (BatchNo (None, 150, 60)      240         conv1d_28[0][0]                  \n","__________________________________________________________________________________________________\n","leaky_re_lu_37 (LeakyReLU)      (None, 150, 60)      0           batch_normalization_37[0][0]     \n","__________________________________________________________________________________________________\n","add_5 (Add)                     (None, 150, 60)      0           leaky_re_lu_37[0][0]             \n","                                                                 add_4[0][0]                      \n","__________________________________________________________________________________________________\n","conv1d_29 (Conv1D)              (None, 150, 60)      32460       add_5[0][0]                      \n","__________________________________________________________________________________________________\n","batch_normalization_38 (BatchNo (None, 150, 60)      240         conv1d_29[0][0]                  \n","__________________________________________________________________________________________________\n","leaky_re_lu_38 (LeakyReLU)      (None, 150, 60)      0           batch_normalization_38[0][0]     \n","__________________________________________________________________________________________________\n","conv1d_30 (Conv1D)              (None, 150, 120)     21720       leaky_re_lu_38[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_39 (BatchNo (None, 150, 120)     480         conv1d_30[0][0]                  \n","__________________________________________________________________________________________________\n","leaky_re_lu_39 (LeakyReLU)      (None, 150, 120)     0           batch_normalization_39[0][0]     \n","__________________________________________________________________________________________________\n","conv1d_31 (Conv1D)              (None, 150, 60)      21660       leaky_re_lu_39[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_40 (BatchNo (None, 150, 60)      240         conv1d_31[0][0]                  \n","__________________________________________________________________________________________________\n","leaky_re_lu_40 (LeakyReLU)      (None, 150, 60)      0           batch_normalization_40[0][0]     \n","__________________________________________________________________________________________________\n","add_6 (Add)                     (None, 150, 60)      0           leaky_re_lu_40[0][0]             \n","                                                                 add_5[0][0]                      \n","__________________________________________________________________________________________________\n","batch_normalization_41 (BatchNo (None, 150, 60)      240         add_6[0][0]                      \n","__________________________________________________________________________________________________\n","global_average_pooling1d (Globa (None, 60)           0           batch_normalization_41[0][0]     \n","__________________________________________________________________________________________________\n","dense (Dense)                   (None, 61)           3721        global_average_pooling1d[0][0]   \n","==================================================================================================\n","Total params: 978,651\n","Trainable params: 973,671\n","Non-trainable params: 4,980\n","__________________________________________________________________________________________________\n","/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"]}],"source":["model = make_CNN_RNN_model(\n","    lr = 0.001,\n","    leakyrelu_alpha = 0.2,\n","    input_kernels = 10,\n","    input_kernel_width = 3,\n","    res_kernels = 60,\n","    res_kernel_width = 3,\n","    res_regularize_coeff=0.1, #0.2\n","    res_num = 7, #5\n","    )\n","\n","model.summary()"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1940: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n","  warnings.warn('`Model.fit_generator` is deprecated and '\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/array_ops.py:5049: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n","Instructions for updating:\n","The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n","Epoch 1/2000\n","34/34 [==============================] - 34s 286ms/step - loss: 260.0372 - accuracy: 0.3709 - val_loss: 175.4861 - val_accuracy: 0.4453\n","\n","Epoch 00001: val_loss improved from inf to 175.48611, saving model to ./save/cnn_gru_best.hdf5\n","Epoch 2/2000\n","34/34 [==============================] - 6s 180ms/step - loss: 130.4279 - accuracy: 0.5496 - val_loss: 89.8384 - val_accuracy: 0.4531\n","\n","Epoch 00002: val_loss improved from 175.48611 to 89.83839, saving model to ./save/cnn_gru_best.hdf5\n","Epoch 3/2000\n","34/34 [==============================] - 6s 180ms/step - loss: 68.3427 - accuracy: 0.6273 - val_loss: 48.1803 - val_accuracy: 0.4414\n","\n","Epoch 00003: val_loss improved from 89.83839 to 48.18031, saving model to ./save/cnn_gru_best.hdf5\n","Epoch 4/2000\n","34/34 [==============================] - 6s 180ms/step - loss: 37.4400 - accuracy: 0.6705 - val_loss: 27.1810 - val_accuracy: 0.4648\n","\n","Epoch 00004: val_loss improved from 48.18031 to 27.18104, saving model to ./save/cnn_gru_best.hdf5\n","Epoch 5/2000\n","34/34 [==============================] - 6s 178ms/step - loss: 21.8001 - accuracy: 0.6599 - val_loss: 16.5203 - val_accuracy: 0.4570\n","\n","Epoch 00005: val_loss improved from 27.18104 to 16.52025, saving model to ./save/cnn_gru_best.hdf5\n","Epoch 6/2000\n","34/34 [==============================] - 6s 178ms/step - loss: 13.3407 - accuracy: 0.6870 - val_loss: 11.3694 - val_accuracy: 0.4570\n","\n","Epoch 00006: val_loss improved from 16.52025 to 11.36938, saving model to ./save/cnn_gru_best.hdf5\n","Epoch 7/2000\n","34/34 [==============================] - 6s 181ms/step - loss: 8.8318 - accuracy: 0.6976 - val_loss: 8.1533 - val_accuracy: 0.4570\n","\n","Epoch 00007: val_loss improved from 11.36938 to 8.15333, saving model to ./save/cnn_gru_best.hdf5\n","Epoch 8/2000\n","34/34 [==============================] - 6s 181ms/step - loss: 6.4488 - accuracy: 0.7100 - val_loss: 6.5948 - val_accuracy: 0.4531\n","\n","Epoch 00008: val_loss improved from 8.15333 to 6.59477, saving model to ./save/cnn_gru_best.hdf5\n","Epoch 9/2000\n","34/34 [==============================] - 6s 182ms/step - loss: 5.3579 - accuracy: 0.6967 - val_loss: 6.0721 - val_accuracy: 0.4453\n","\n","Epoch 00009: val_loss improved from 6.59477 to 6.07207, saving model to ./save/cnn_gru_best.hdf5\n","Epoch 10/2000\n","34/34 [==============================] - 6s 180ms/step - loss: 4.4535 - accuracy: 0.7215 - val_loss: 6.5092 - val_accuracy: 0.0117\n","\n","Epoch 00010: val_loss did not improve from 6.07207\n","Epoch 11/2000\n","34/34 [==============================] - 6s 180ms/step - loss: 3.9494 - accuracy: 0.7289 - val_loss: 5.4179 - val_accuracy: 0.0547\n","\n","Epoch 00011: val_loss improved from 6.07207 to 5.41786, saving model to ./save/cnn_gru_best.hdf5\n","Epoch 12/2000\n","34/34 [==============================] - 6s 179ms/step - loss: 3.6632 - accuracy: 0.7408 - val_loss: 6.3352 - val_accuracy: 0.0195\n","\n","Epoch 00012: val_loss did not improve from 5.41786\n","Epoch 13/2000\n","34/34 [==============================] - 6s 178ms/step - loss: 3.4946 - accuracy: 0.7477 - val_loss: 5.8463 - val_accuracy: 0.0898\n","\n","Epoch 00013: val_loss did not improve from 5.41786\n","Epoch 14/2000\n","34/34 [==============================] - 6s 180ms/step - loss: 3.3344 - accuracy: 0.7537 - val_loss: 5.1071 - val_accuracy: 0.1211\n","\n","Epoch 00014: val_loss improved from 5.41786 to 5.10715, saving model to ./save/cnn_gru_best.hdf5\n","Epoch 15/2000\n","34/34 [==============================] - 6s 183ms/step - loss: 3.1377 - accuracy: 0.7698 - val_loss: 4.5889 - val_accuracy: 0.2617\n","\n","Epoch 00015: val_loss improved from 5.10715 to 4.58894, saving model to ./save/cnn_gru_best.hdf5\n","Epoch 16/2000\n","34/34 [==============================] - 6s 180ms/step - loss: 3.1237 - accuracy: 0.7624 - val_loss: 3.9737 - val_accuracy: 0.4766\n","\n","Epoch 00016: val_loss improved from 4.58894 to 3.97373, saving model to ./save/cnn_gru_best.hdf5\n","Epoch 17/2000\n","34/34 [==============================] - 6s 182ms/step - loss: 3.1677 - accuracy: 0.7661 - val_loss: 4.1768 - val_accuracy: 0.3438\n","\n","Epoch 00017: val_loss did not improve from 3.97373\n","Epoch 18/2000\n","34/34 [==============================] - 6s 182ms/step - loss: 2.9408 - accuracy: 0.7918 - val_loss: 3.0078 - val_accuracy: 0.4883\n","\n","Epoch 00018: val_loss improved from 3.97373 to 3.00776, saving model to ./save/cnn_gru_best.hdf5\n","Epoch 19/2000\n","34/34 [==============================] - 6s 180ms/step - loss: 2.8866 - accuracy: 0.7730 - val_loss: 2.9909 - val_accuracy: 0.5391\n","\n","Epoch 00019: val_loss improved from 3.00776 to 2.99089, saving model to ./save/cnn_gru_best.hdf5\n","Epoch 20/2000\n","34/34 [==============================] - 6s 181ms/step - loss: 2.9499 - accuracy: 0.7932 - val_loss: 4.1934 - val_accuracy: 0.3359\n","\n","Epoch 00020: val_loss did not improve from 2.99089\n","Epoch 21/2000\n","34/34 [==============================] - 6s 179ms/step - loss: 2.9446 - accuracy: 0.7739 - val_loss: 3.0021 - val_accuracy: 0.5156\n","\n","Epoch 00021: val_loss did not improve from 2.99089\n","Epoch 22/2000\n","34/34 [==============================] - 6s 181ms/step - loss: 2.6145 - accuracy: 0.8125 - val_loss: 1.9123 - val_accuracy: 0.6836\n","\n","Epoch 00022: val_loss improved from 2.99089 to 1.91225, saving model to ./save/cnn_gru_best.hdf5\n","Epoch 23/2000\n","34/34 [==============================] - 6s 178ms/step - loss: 2.3067 - accuracy: 0.8286 - val_loss: 1.8843 - val_accuracy: 0.6836\n","\n","Epoch 00023: val_loss improved from 1.91225 to 1.88430, saving model to ./save/cnn_gru_best.hdf5\n","Epoch 24/2000\n","34/34 [==============================] - 6s 180ms/step - loss: 2.2806 - accuracy: 0.8226 - val_loss: 2.1527 - val_accuracy: 0.6250\n","\n","Epoch 00024: val_loss did not improve from 1.88430\n","Epoch 25/2000\n","34/34 [==============================] - 6s 181ms/step - loss: 2.1662 - accuracy: 0.8272 - val_loss: 1.9749 - val_accuracy: 0.6562\n","\n","Epoch 00025: val_loss did not improve from 1.88430\n","Epoch 26/2000\n","34/34 [==============================] - 6s 179ms/step - loss: 2.0239 - accuracy: 0.8415 - val_loss: 2.0399 - val_accuracy: 0.6484\n","\n","Epoch 00026: val_loss did not improve from 1.88430\n","Epoch 27/2000\n","34/34 [==============================] - 6s 180ms/step - loss: 2.0343 - accuracy: 0.8350 - val_loss: 1.8794 - val_accuracy: 0.7031\n","\n","Epoch 00027: val_loss improved from 1.88430 to 1.87936, saving model to ./save/cnn_gru_best.hdf5\n","Epoch 28/2000\n","34/34 [==============================] - 6s 180ms/step - loss: 1.9527 - accuracy: 0.8415 - val_loss: 1.4441 - val_accuracy: 0.7383\n","\n","Epoch 00028: val_loss improved from 1.87936 to 1.44411, saving model to ./save/cnn_gru_best.hdf5\n","Epoch 29/2000\n","34/34 [==============================] - 6s 180ms/step - loss: 1.8130 - accuracy: 0.8525 - val_loss: 1.3833 - val_accuracy: 0.7344\n","\n","Epoch 00029: val_loss improved from 1.44411 to 1.38326, saving model to ./save/cnn_gru_best.hdf5\n","Epoch 30/2000\n","34/34 [==============================] - 6s 181ms/step - loss: 1.7967 - accuracy: 0.8506 - val_loss: 1.3595 - val_accuracy: 0.7461\n","\n","Epoch 00030: val_loss improved from 1.38326 to 1.35945, saving model to ./save/cnn_gru_best.hdf5\n","Epoch 31/2000\n","34/34 [==============================] - 6s 180ms/step - loss: 1.6682 - accuracy: 0.8598 - val_loss: 1.4181 - val_accuracy: 0.7109\n","\n","Epoch 00031: val_loss did not improve from 1.35945\n","Epoch 32/2000\n","34/34 [==============================] - 6s 180ms/step - loss: 1.6740 - accuracy: 0.8667 - val_loss: 1.3403 - val_accuracy: 0.7500\n","\n","Epoch 00032: val_loss improved from 1.35945 to 1.34029, saving model to ./save/cnn_gru_best.hdf5\n","Epoch 33/2000\n","34/34 [==============================] - 6s 179ms/step - loss: 1.6727 - accuracy: 0.8649 - val_loss: 1.4425 - val_accuracy: 0.7070\n","\n","Epoch 00033: val_loss did not improve from 1.34029\n","Epoch 34/2000\n","34/34 [==============================] - 6s 180ms/step - loss: 1.5488 - accuracy: 0.8709 - val_loss: 1.2491 - val_accuracy: 0.7344\n","\n","Epoch 00034: val_loss improved from 1.34029 to 1.24910, saving model to ./save/cnn_gru_best.hdf5\n","Epoch 35/2000\n","34/34 [==============================] - 6s 186ms/step - loss: 1.4062 - accuracy: 0.8856 - val_loss: 1.5451 - val_accuracy: 0.6680\n","\n","Epoch 00035: val_loss did not improve from 1.24910\n","Epoch 36/2000\n","34/34 [==============================] - 6s 179ms/step - loss: 1.3842 - accuracy: 0.8833 - val_loss: 1.4417 - val_accuracy: 0.6758\n","\n","Epoch 00036: val_loss did not improve from 1.24910\n","Epoch 37/2000\n","34/34 [==============================] - 6s 179ms/step - loss: 1.2895 - accuracy: 0.8994 - val_loss: 1.2075 - val_accuracy: 0.7656\n","\n","Epoch 00037: val_loss improved from 1.24910 to 1.20751, saving model to ./save/cnn_gru_best.hdf5\n","Epoch 38/2000\n","34/34 [==============================] - 6s 179ms/step - loss: 1.5074 - accuracy: 0.8690 - val_loss: 1.3802 - val_accuracy: 0.7305\n","\n","Epoch 00038: val_loss did not improve from 1.20751\n","Epoch 39/2000\n","34/34 [==============================] - 6s 180ms/step - loss: 1.3262 - accuracy: 0.8888 - val_loss: 1.2529 - val_accuracy: 0.7422\n","\n","Epoch 00039: val_loss did not improve from 1.20751\n","Epoch 40/2000\n","34/34 [==============================] - 6s 180ms/step - loss: 1.2658 - accuracy: 0.8938 - val_loss: 1.0153 - val_accuracy: 0.7891\n","\n","Epoch 00040: val_loss improved from 1.20751 to 1.01526, saving model to ./save/cnn_gru_best.hdf5\n","Epoch 41/2000\n","34/34 [==============================] - 6s 180ms/step - loss: 1.3085 - accuracy: 0.8842 - val_loss: 1.1287 - val_accuracy: 0.7578\n","\n","Epoch 00041: val_loss did not improve from 1.01526\n","Epoch 42/2000\n","34/34 [==============================] - 6s 178ms/step - loss: 1.2045 - accuracy: 0.8994 - val_loss: 1.0349 - val_accuracy: 0.7695\n","\n","Epoch 00042: val_loss did not improve from 1.01526\n","Epoch 43/2000\n","34/34 [==============================] - 6s 177ms/step - loss: 1.1080 - accuracy: 0.9049 - val_loss: 1.0029 - val_accuracy: 0.7773\n","\n","Epoch 00043: val_loss improved from 1.01526 to 1.00290, saving model to ./save/cnn_gru_best.hdf5\n","Epoch 44/2000\n","34/34 [==============================] - 6s 180ms/step - loss: 1.2092 - accuracy: 0.8971 - val_loss: 1.0521 - val_accuracy: 0.7930\n","\n","Epoch 00044: val_loss did not improve from 1.00290\n","Epoch 45/2000\n","34/34 [==============================] - 6s 180ms/step - loss: 1.1905 - accuracy: 0.8952 - val_loss: 1.0368 - val_accuracy: 0.7852\n","\n","Epoch 00045: val_loss did not improve from 1.00290\n","Epoch 46/2000\n","34/34 [==============================] - 6s 180ms/step - loss: 1.0858 - accuracy: 0.9127 - val_loss: 1.0825 - val_accuracy: 0.7656\n","\n","Epoch 00046: val_loss did not improve from 1.00290\n","Epoch 47/2000\n","34/34 [==============================] - 6s 179ms/step - loss: 1.1587 - accuracy: 0.9021 - val_loss: 1.0488 - val_accuracy: 0.7734\n","\n","Epoch 00047: val_loss did not improve from 1.00290\n","Epoch 48/2000\n","34/34 [==============================] - 6s 180ms/step - loss: 1.1214 - accuracy: 0.9012 - val_loss: 1.0686 - val_accuracy: 0.7656\n","\n","Epoch 00048: val_loss did not improve from 1.00290\n","Epoch 49/2000\n","34/34 [==============================] - 6s 179ms/step - loss: 1.0551 - accuracy: 0.9085 - val_loss: 1.0069 - val_accuracy: 0.7773\n","\n","Epoch 00049: val_loss did not improve from 1.00290\n","Epoch 50/2000\n","34/34 [==============================] - 6s 179ms/step - loss: 1.0095 - accuracy: 0.9154 - val_loss: 1.0046 - val_accuracy: 0.7773\n","\n","Epoch 00050: val_loss did not improve from 1.00290\n","Epoch 51/2000\n","34/34 [==============================] - 6s 179ms/step - loss: 1.0468 - accuracy: 0.9150 - val_loss: 1.0211 - val_accuracy: 0.7734\n","\n","Epoch 00051: val_loss did not improve from 1.00290\n","Epoch 52/2000\n","34/34 [==============================] - 6s 179ms/step - loss: 1.0323 - accuracy: 0.9053 - val_loss: 1.0183 - val_accuracy: 0.7891\n","\n","Epoch 00052: val_loss did not improve from 1.00290\n","Epoch 53/2000\n","34/34 [==============================] - 6s 180ms/step - loss: 0.9418 - accuracy: 0.9320 - val_loss: 0.9949 - val_accuracy: 0.7969\n","\n","Epoch 00053: val_loss improved from 1.00290 to 0.99487, saving model to ./save/cnn_gru_best.hdf5\n","Epoch 54/2000\n","34/34 [==============================] - 6s 179ms/step - loss: 1.0129 - accuracy: 0.9173 - val_loss: 0.9671 - val_accuracy: 0.7891\n","\n","Epoch 00054: val_loss improved from 0.99487 to 0.96713, saving model to ./save/cnn_gru_best.hdf5\n","Epoch 55/2000\n","34/34 [==============================] - 6s 180ms/step - loss: 1.0475 - accuracy: 0.9118 - val_loss: 0.9837 - val_accuracy: 0.7891\n","\n","Epoch 00055: val_loss did not improve from 0.96713\n","Epoch 56/2000\n","34/34 [==============================] - 6s 180ms/step - loss: 0.9938 - accuracy: 0.9150 - val_loss: 0.9689 - val_accuracy: 0.7852\n","\n","Epoch 00056: val_loss did not improve from 0.96713\n","Epoch 57/2000\n","34/34 [==============================] - 6s 180ms/step - loss: 0.9288 - accuracy: 0.9288 - val_loss: 0.9621 - val_accuracy: 0.7930\n","\n","Epoch 00057: val_loss improved from 0.96713 to 0.96213, saving model to ./save/cnn_gru_best.hdf5\n","Epoch 58/2000\n","34/34 [==============================] - 6s 179ms/step - loss: 0.9173 - accuracy: 0.9223 - val_loss: 0.9479 - val_accuracy: 0.7969\n","\n","Epoch 00058: val_loss improved from 0.96213 to 0.94787, saving model to ./save/cnn_gru_best.hdf5\n","Epoch 59/2000\n","34/34 [==============================] - 6s 181ms/step - loss: 0.8810 - accuracy: 0.9324 - val_loss: 0.9500 - val_accuracy: 0.7969\n","\n","Epoch 00059: val_loss did not improve from 0.94787\n","Epoch 60/2000\n","34/34 [==============================] - 6s 179ms/step - loss: 0.8204 - accuracy: 0.9315 - val_loss: 0.9427 - val_accuracy: 0.7969\n","\n","Epoch 00060: val_loss improved from 0.94787 to 0.94274, saving model to ./save/cnn_gru_best.hdf5\n","Epoch 61/2000\n","34/34 [==============================] - 6s 178ms/step - loss: 0.7796 - accuracy: 0.9347 - val_loss: 0.8684 - val_accuracy: 0.8086\n","\n","Epoch 00061: val_loss improved from 0.94274 to 0.86843, saving model to ./save/cnn_gru_best.hdf5\n","Epoch 62/2000\n","34/34 [==============================] - 6s 180ms/step - loss: 0.8342 - accuracy: 0.9393 - val_loss: 0.9495 - val_accuracy: 0.7930\n","\n","Epoch 00062: val_loss did not improve from 0.86843\n","Epoch 63/2000\n","34/34 [==============================] - 6s 179ms/step - loss: 0.8038 - accuracy: 0.9389 - val_loss: 0.9446 - val_accuracy: 0.8008\n","\n","Epoch 00063: val_loss did not improve from 0.86843\n","Epoch 64/2000\n","34/34 [==============================] - 6s 179ms/step - loss: 0.7976 - accuracy: 0.9407 - val_loss: 0.9354 - val_accuracy: 0.8047\n","\n","Epoch 00064: val_loss did not improve from 0.86843\n","Epoch 65/2000\n","34/34 [==============================] - 6s 181ms/step - loss: 0.8951 - accuracy: 0.9242 - val_loss: 0.9221 - val_accuracy: 0.8008\n","\n","Epoch 00065: val_loss did not improve from 0.86843\n","Epoch 66/2000\n","34/34 [==============================] - 6s 181ms/step - loss: 0.8450 - accuracy: 0.9329 - val_loss: 0.9404 - val_accuracy: 0.8008\n","\n","Epoch 00066: val_loss did not improve from 0.86843\n","Epoch 67/2000\n","34/34 [==============================] - 6s 180ms/step - loss: 0.8052 - accuracy: 0.9338 - val_loss: 0.9375 - val_accuracy: 0.8008\n","\n","Epoch 00067: val_loss did not improve from 0.86843\n","Epoch 68/2000\n","34/34 [==============================] - 6s 180ms/step - loss: 0.8698 - accuracy: 0.9274 - val_loss: 0.8911 - val_accuracy: 0.8164\n","\n","Epoch 00068: val_loss did not improve from 0.86843\n","Epoch 69/2000\n","34/34 [==============================] - 6s 179ms/step - loss: 0.9246 - accuracy: 0.9200 - val_loss: 1.0106 - val_accuracy: 0.7812\n","\n","Epoch 00069: val_loss did not improve from 0.86843\n","Epoch 70/2000\n","34/34 [==============================] - 6s 178ms/step - loss: 0.8657 - accuracy: 0.9311 - val_loss: 0.9312 - val_accuracy: 0.7969\n","\n","Epoch 00070: val_loss did not improve from 0.86843\n","Epoch 71/2000\n","34/34 [==============================] - 6s 180ms/step - loss: 0.8265 - accuracy: 0.9329 - val_loss: 1.0357 - val_accuracy: 0.7891\n","\n","Epoch 00071: val_loss did not improve from 0.86843\n","Epoch 72/2000\n","34/34 [==============================] - 6s 178ms/step - loss: 0.7635 - accuracy: 0.9403 - val_loss: 0.9423 - val_accuracy: 0.7969\n","\n","Epoch 00072: val_loss did not improve from 0.86843\n","Epoch 73/2000\n","34/34 [==============================] - 6s 181ms/step - loss: 0.7343 - accuracy: 0.9476 - val_loss: 0.9508 - val_accuracy: 0.7891\n","\n","Epoch 00073: val_loss did not improve from 0.86843\n","Epoch 74/2000\n","34/34 [==============================] - 6s 179ms/step - loss: 0.8015 - accuracy: 0.9334 - val_loss: 0.9105 - val_accuracy: 0.8086\n","\n","Epoch 00074: val_loss did not improve from 0.86843\n","Epoch 75/2000\n","34/34 [==============================] - 6s 179ms/step - loss: 0.8830 - accuracy: 0.9223 - val_loss: 0.9438 - val_accuracy: 0.8008\n","\n","Epoch 00075: val_loss did not improve from 0.86843\n","Epoch 76/2000\n","34/34 [==============================] - 6s 183ms/step - loss: 0.8176 - accuracy: 0.9320 - val_loss: 0.8850 - val_accuracy: 0.8125\n","\n","Epoch 00076: val_loss did not improve from 0.86843\n","Epoch 77/2000\n","34/34 [==============================] - 6s 181ms/step - loss: 0.8097 - accuracy: 0.9343 - val_loss: 0.9614 - val_accuracy: 0.8008\n","\n","Epoch 00077: val_loss did not improve from 0.86843\n","Epoch 78/2000\n","34/34 [==============================] - 6s 179ms/step - loss: 0.8862 - accuracy: 0.9274 - val_loss: 0.9009 - val_accuracy: 0.8008\n","\n","Epoch 00078: val_loss did not improve from 0.86843\n","Epoch 79/2000\n","34/34 [==============================] - 6s 181ms/step - loss: 0.7739 - accuracy: 0.9380 - val_loss: 0.9268 - val_accuracy: 0.7930\n","\n","Epoch 00079: val_loss did not improve from 0.86843\n","Epoch 80/2000\n","34/34 [==============================] - 6s 182ms/step - loss: 0.8281 - accuracy: 0.9251 - val_loss: 0.9478 - val_accuracy: 0.8047\n","\n","Epoch 00080: val_loss did not improve from 0.86843\n","Epoch 81/2000\n","34/34 [==============================] - 6s 179ms/step - loss: 0.7886 - accuracy: 0.9426 - val_loss: 0.9144 - val_accuracy: 0.8125\n","\n","Epoch 00081: val_loss did not improve from 0.86843\n","Epoch 00081: early stopping\n"]}],"source":["\n","save_best = tf.keras.callbacks.ModelCheckpoint(\n","    filepath=checkpoint_filepath, monitor='val_loss', verbose=1, save_best_only=True,\n","    save_weights_only=True, mode='auto', save_freq='epoch', options=None)\n","\n","early_stop = tf.keras.callbacks.EarlyStopping(\n","    monitor='val_loss',min_delta=0.0001,\n","    patience=20,verbose=1)\n","\n","history = model.fit_generator(\n","    generator=train_loader,\n","    validation_data=valid_loader,\n","    epochs=2000,\n","    callbacks=[save_best,early_stop,lr_scheduler],\n","    class_weight=class_weight_dict)\n",""]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1973: UserWarning: `Model.evaluate_generator` is deprecated and will be removed in a future version. Please use `Model.evaluate`, which supports generators.\n","  warnings.warn('`Model.evaluate_generator` is deprecated and '\n","1/1 [==============================] - 1s 1s/step - loss: 0.7734 - accuracy: 0.8336\n"]},{"output_type":"execute_result","data":{"text/plain":["[0.7734295129776001, 0.8335999846458435]"]},"metadata":{},"execution_count":6}],"source":["model.load_weights(checkpoint_filepath)\n","model.evaluate_generator(generator=test_loader,verbose=1)"]}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"codemirror_mode":{"name":"ipython","version":2},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython2","version":2},"orig_nbformat":4}}