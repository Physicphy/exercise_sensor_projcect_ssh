>> Start! : Tue Jul 27 13:44:25 2021
>> data preprocessing
>> X_train, X_test, y_train, y_test --(save)--> *.npy, *.csv
labels_to_csv at ./data/y_train.csv
labels_to_csv at ./data/y_test.csv
features_to_npy at ./data/X_train : 250/2500
features_to_npy at ./data/X_train : 500/2500
features_to_npy at ./data/X_train : 750/2500
features_to_npy at ./data/X_train : 1000/2500
features_to_npy at ./data/X_train : 1250/2500
features_to_npy at ./data/X_train : 1500/2500
features_to_npy at ./data/X_train : 1750/2500
features_to_npy at ./data/X_train : 2000/2500
features_to_npy at ./data/X_train : 2250/2500
features_to_npy at ./data/X_train : 2500/2500
features_to_npy at ./data/X_test : 62/625
features_to_npy at ./data/X_test : 124/625
features_to_npy at ./data/X_test : 186/625
features_to_npy at ./data/X_test : 248/625
features_to_npy at ./data/X_test : 310/625
features_to_npy at ./data/X_test : 372/625
features_to_npy at ./data/X_test : 434/625
features_to_npy at ./data/X_test : 496/625
features_to_npy at ./data/X_test : 558/625
features_to_npy at ./data/X_test : 620/625
features_to_npy at ./data/X_test : 625/625
>> model building
>>> model : nonBN_CNN_RNN_Resnet
>>> model_parameter :
{'leakyrelu_alpha': 0.1, 'input_kernels': 20, 'input_kernel_width': 3, 'input_regularize_coeff': 0.0001, 'res_kernels': 60, 'res_kernel_width': 3, 'res_regularize_coeff': 0.01, 'res_num': 5}
>>> num_of_fold : 10
>>> optimizer : Adam {'learning_rate': 0.001}
>>> rot_prob: 0.5, perm_prob: 0.5
>> model training
>> start - Process-1 at Tue Jul 27 13:45:01 2021
Epoch 1/1000
34/34 - 98s - loss: 27.7006 - accuracy: 0.4122 - val_loss: 24.1906 - val_accuracy: 0.4609

Epoch 00001: val_loss improved from inf to 24.19063, saving model to ./save/nonBN_CNN_RNN_Resnet_5_use_mp_alpha_0.1_res_num_5_opt_Adam_fold_0.hdf5
Epoch 2/1000
34/34 - 15s - loss: 21.5469 - accuracy: 0.5055 - val_loss: 19.2486 - val_accuracy: 0.4727

Epoch 00002: val_loss improved from 24.19063 to 19.24862, saving model to ./save/nonBN_CNN_RNN_Resnet_5_use_mp_alpha_0.1_res_num_5_opt_Adam_fold_0.hdf5
Epoch 3/1000
34/34 - 15s - loss: 17.1090 - accuracy: 0.5211 - val_loss: 15.3190 - val_accuracy: 0.5156

Epoch 00003: val_loss improved from 19.24862 to 15.31899, saving model to ./save/nonBN_CNN_RNN_Resnet_5_use_mp_alpha_0.1_res_num_5_opt_Adam_fold_0.hdf5
Epoch 4/1000
34/34 - 15s - loss: 13.8008 - accuracy: 0.5423 - val_loss: 12.4224 - val_accuracy: 0.5195

Epoch 00004: val_loss improved from 15.31899 to 12.42237, saving model to ./save/nonBN_CNN_RNN_Resnet_5_use_mp_alpha_0.1_res_num_5_opt_Adam_fold_0.hdf5
Epoch 5/1000
34/34 - 15s - loss: 11.4121 - accuracy: 0.5584 - val_loss: 10.3389 - val_accuracy: 0.5312

Epoch 00005: val_loss improved from 12.42237 to 10.33888, saving model to ./save/nonBN_CNN_RNN_Resnet_5_use_mp_alpha_0.1_res_num_5_opt_Adam_fold_0.hdf5
Epoch 6/1000
34/34 - 15s - loss: 9.5718 - accuracy: 0.5630 - val_loss: 8.8022 - val_accuracy: 0.5195

Epoch 00006: val_loss improved from 10.33888 to 8.80221, saving model to ./save/nonBN_CNN_RNN_Resnet_5_use_mp_alpha_0.1_res_num_5_opt_Adam_fold_0.hdf5
Epoch 7/1000
34/34 - 15s - loss: 8.1379 - accuracy: 0.5809 - val_loss: 7.7354 - val_accuracy: 0.5664

Epoch 00007: val_loss improved from 8.80221 to 7.73540, saving model to ./save/nonBN_CNN_RNN_Resnet_5_use_mp_alpha_0.1_res_num_5_opt_Adam_fold_0.hdf5
Epoch 8/1000
34/34 - 15s - loss: 7.1100 - accuracy: 0.5938 - val_loss: 6.6962 - val_accuracy: 0.5586

Epoch 00008: val_loss improved from 7.73540 to 6.69620, saving model to ./save/nonBN_CNN_RNN_Resnet_5_use_mp_alpha_0.1_res_num_5_opt_Adam_fold_0.hdf5
Epoch 9/1000
34/34 - 15s - loss: 6.2385 - accuracy: 0.5938 - val_loss: 6.0326 - val_accuracy: 0.5430

Epoch 00009: val_loss improved from 6.69620 to 6.03255, saving model to ./save/nonBN_CNN_RNN_Resnet_5_use_mp_alpha_0.1_res_num_5_opt_Adam_fold_0.hdf5
Epoch 10/1000
34/34 - 15s - loss: 5.5350 - accuracy: 0.5993 - val_loss: 5.2058 - val_accuracy: 0.6016

Epoch 00010: val_loss improved from 6.03255 to 5.20582, saving model to ./save/nonBN_CNN_RNN_Resnet_5_use_mp_alpha_0.1_res_num_5_opt_Adam_fold_0.hdf5
Epoch 11/1000
34/34 - 15s - loss: 4.9243 - accuracy: 0.6222 - val_loss: 4.5758 - val_accuracy: 0.6406

Epoch 00011: val_loss improved from 5.20582 to 4.57581, saving model to ./save/nonBN_CNN_RNN_Resnet_5_use_mp_alpha_0.1_res_num_5_opt_Adam_fold_0.hdf5
Epoch 12/1000
34/34 - 15s - loss: 4.4372 - accuracy: 0.6406 - val_loss: 4.2432 - val_accuracy: 0.6211

Epoch 00012: val_loss improved from 4.57581 to 4.24323, saving model to ./save/nonBN_CNN_RNN_Resnet_5_use_mp_alpha_0.1_res_num_5_opt_Adam_fold_0.hdf5
Epoch 13/1000
34/34 - 15s - loss: 4.1479 - accuracy: 0.6153 - val_loss: 4.0471 - val_accuracy: 0.5977

Epoch 00013: val_loss improved from 4.24323 to 4.04707, saving model to ./save/nonBN_CNN_RNN_Resnet_5_use_mp_alpha_0.1_res_num_5_opt_Adam_fold_0.hdf5
Epoch 14/1000
34/34 - 15s - loss: 3.7407 - accuracy: 0.6498 - val_loss: 3.5960 - val_accuracy: 0.6289

Epoch 00014: val_loss improved from 4.04707 to 3.59600, saving model to ./save/nonBN_CNN_RNN_Resnet_5_use_mp_alpha_0.1_res_num_5_opt_Adam_fold_0.hdf5
Epoch 15/1000
34/34 - 15s - loss: 3.5186 - accuracy: 0.6466 - val_loss: 3.4551 - val_accuracy: 0.6016

Epoch 00015: val_loss improved from 3.59600 to 3.45513, saving model to ./save/nonBN_CNN_RNN_Resnet_5_use_mp_alpha_0.1_res_num_5_opt_Adam_fold_0.hdf5
Epoch 16/1000
34/34 - 14s - loss: 3.2222 - accuracy: 0.6494 - val_loss: 3.0190 - val_accuracy: 0.6680

Epoch 00016: val_loss improved from 3.45513 to 3.01897, saving model to ./save/nonBN_CNN_RNN_Resnet_5_use_mp_alpha_0.1_res_num_5_opt_Adam_fold_0.hdf5
Epoch 17/1000
34/34 - 14s - loss: 2.9886 - accuracy: 0.6535 - val_loss: 2.9413 - val_accuracy: 0.6484

Epoch 00017: val_loss improved from 3.01897 to 2.94132, saving model to ./save/nonBN_CNN_RNN_Resnet_5_use_mp_alpha_0.1_res_num_5_opt_Adam_fold_0.hdf5
Epoch 18/1000
34/34 - 14s - loss: 2.8495 - accuracy: 0.6544 - val_loss: 2.8121 - val_accuracy: 0.6445

Epoch 00018: val_loss improved from 2.94132 to 2.81206, saving model to ./save/nonBN_CNN_RNN_Resnet_5_use_mp_alpha_0.1_res_num_5_opt_Adam_fold_0.hdf5
Epoch 19/1000
34/34 - 14s - loss: 2.6015 - accuracy: 0.6811 - val_loss: 2.5064 - val_accuracy: 0.6797

Epoch 00019: val_loss improved from 2.81206 to 2.50636, saving model to ./save/nonBN_CNN_RNN_Resnet_5_use_mp_alpha_0.1_res_num_5_opt_Adam_fold_0.hdf5
Epoch 20/1000
34/34 - 14s - loss: 2.5119 - accuracy: 0.6714 - val_loss: 2.4594 - val_accuracy: 0.6523

Epoch 00020: val_loss improved from 2.50636 to 2.45942, saving model to ./save/nonBN_CNN_RNN_Resnet_5_use_mp_alpha_0.1_res_num_5_opt_Adam_fold_0.hdf5
Epoch 21/1000
34/34 - 14s - loss: 2.3034 - accuracy: 0.6903 - val_loss: 2.3569 - val_accuracy: 0.6328

Epoch 00021: val_loss improved from 2.45942 to 2.35691, saving model to ./save/nonBN_CNN_RNN_Resnet_5_use_mp_alpha_0.1_res_num_5_opt_Adam_fold_0.hdf5
Epoch 22/1000
34/34 - 14s - loss: 2.2068 - accuracy: 0.6949 - val_loss: 2.2152 - val_accuracy: 0.6758

Epoch 00022: val_loss improved from 2.35691 to 2.21516, saving model to ./save/nonBN_CNN_RNN_Resnet_5_use_mp_alpha_0.1_res_num_5_opt_Adam_fold_0.hdf5
Epoch 23/1000
34/34 - 14s - loss: 2.0656 - accuracy: 0.7160 - val_loss: 2.1128 - val_accuracy: 0.6953

Epoch 00023: val_loss improved from 2.21516 to 2.11279, saving model to ./save/nonBN_CNN_RNN_Resnet_5_use_mp_alpha_0.1_res_num_5_opt_Adam_fold_0.hdf5
Epoch 24/1000
34/34 - 14s - loss: 2.0132 - accuracy: 0.7119 - val_loss: 2.1200 - val_accuracy: 0.6914

Epoch 00024: val_loss did not improve from 2.11279
Epoch 25/1000
34/34 - 14s - loss: 1.9860 - accuracy: 0.7073 - val_loss: 1.9833 - val_accuracy: 0.7109

Epoch 00025: val_loss improved from 2.11279 to 1.98331, saving model to ./save/nonBN_CNN_RNN_Resnet_5_use_mp_alpha_0.1_res_num_5_opt_Adam_fold_0.hdf5
Epoch 26/1000
34/34 - 14s - loss: 1.9374 - accuracy: 0.7008 - val_loss: 1.9975 - val_accuracy: 0.6719

Epoch 00026: val_loss did not improve from 1.98331
Epoch 27/1000
34/34 - 14s - loss: 1.9889 - accuracy: 0.6636 - val_loss: 2.0107 - val_accuracy: 0.6641

Epoch 00027: val_loss did not improve from 1.98331
Epoch 28/1000
34/34 - 14s - loss: 1.7995 - accuracy: 0.7114 - val_loss: 1.8062 - val_accuracy: 0.7148

Epoch 00028: val_loss improved from 1.98331 to 1.80622, saving model to ./save/nonBN_CNN_RNN_Resnet_5_use_mp_alpha_0.1_res_num_5_opt_Adam_fold_0.hdf5
Epoch 29/1000
34/34 - 14s - loss: 1.7524 - accuracy: 0.7169 - val_loss: 1.7491 - val_accuracy: 0.7188

Epoch 00029: val_loss improved from 1.80622 to 1.74912, saving model to ./save/nonBN_CNN_RNN_Resnet_5_use_mp_alpha_0.1_res_num_5_opt_Adam_fold_0.hdf5
Epoch 30/1000
34/34 - 14s - loss: 1.7105 - accuracy: 0.7174 - val_loss: 1.7703 - val_accuracy: 0.6953

Epoch 00030: val_loss did not improve from 1.74912
Epoch 31/1000
34/34 - 14s - loss: 1.6664 - accuracy: 0.7270 - val_loss: 1.7245 - val_accuracy: 0.6992

Epoch 00031: val_loss improved from 1.74912 to 1.72453, saving model to ./save/nonBN_CNN_RNN_Resnet_5_use_mp_alpha_0.1_res_num_5_opt_Adam_fold_0.hdf5
Epoch 32/1000
34/34 - 14s - loss: 1.6076 - accuracy: 0.7243 - val_loss: 1.6309 - val_accuracy: 0.7031

Epoch 00032: val_loss improved from 1.72453 to 1.63093, saving model to ./save/nonBN_CNN_RNN_Resnet_5_use_mp_alpha_0.1_res_num_5_opt_Adam_fold_0.hdf5
Epoch 33/1000
34/34 - 14s - loss: 1.6092 - accuracy: 0.7210 - val_loss: 1.5943 - val_accuracy: 0.7344

Epoch 00033: val_loss improved from 1.63093 to 1.59435, saving model to ./save/nonBN_CNN_RNN_Resnet_5_use_mp_alpha_0.1_res_num_5_opt_Adam_fold_0.hdf5
Epoch 34/1000
34/34 - 14s - loss: 1.5105 - accuracy: 0.7307 - val_loss: 1.6237 - val_accuracy: 0.7305

Epoch 00034: val_loss did not improve from 1.59435
Epoch 35/1000
34/34 - 14s - loss: 1.5216 - accuracy: 0.7279 - val_loss: 1.6181 - val_accuracy: 0.7266

Epoch 00035: val_loss did not improve from 1.59435
Epoch 36/1000
34/34 - 14s - loss: 1.5408 - accuracy: 0.7109 - val_loss: 1.6022 - val_accuracy: 0.6992

Epoch 00036: val_loss did not improve from 1.59435
Epoch 37/1000
34/34 - 14s - loss: 1.4500 - accuracy: 0.7367 - val_loss: 1.4993 - val_accuracy: 0.7188

Epoch 00037: val_loss improved from 1.59435 to 1.49933, saving model to ./save/nonBN_CNN_RNN_Resnet_5_use_mp_alpha_0.1_res_num_5_opt_Adam_fold_0.hdf5
Epoch 38/1000
34/34 - 14s - loss: 1.4363 - accuracy: 0.7403 - val_loss: 1.5205 - val_accuracy: 0.7305

Epoch 00038: val_loss did not improve from 1.49933
Epoch 39/1000
34/34 - 14s - loss: 1.3985 - accuracy: 0.7449 - val_loss: 1.4843 - val_accuracy: 0.7227

Epoch 00039: val_loss improved from 1.49933 to 1.48433, saving model to ./save/nonBN_CNN_RNN_Resnet_5_use_mp_alpha_0.1_res_num_5_opt_Adam_fold_0.hdf5
Epoch 40/1000
34/34 - 14s - loss: 1.3329 - accuracy: 0.7578 - val_loss: 1.4370 - val_accuracy: 0.7461

Epoch 00040: val_loss improved from 1.48433 to 1.43702, saving model to ./save/nonBN_CNN_RNN_Resnet_5_use_mp_alpha_0.1_res_num_5_opt_Adam_fold_0.hdf5
Epoch 41/1000
34/34 - 14s - loss: 1.3717 - accuracy: 0.7408 - val_loss: 1.5315 - val_accuracy: 0.6992

Epoch 00041: val_loss did not improve from 1.43702
Epoch 42/1000
34/34 - 14s - loss: 1.3660 - accuracy: 0.7468 - val_loss: 1.5382 - val_accuracy: 0.6953

Epoch 00042: val_loss did not improve from 1.43702
Epoch 43/1000
34/34 - 14s - loss: 1.2185 - accuracy: 0.7835 - val_loss: 1.2678 - val_accuracy: 0.8047

Epoch 00043: val_loss improved from 1.43702 to 1.26776, saving model to ./save/nonBN_CNN_RNN_Resnet_5_use_mp_alpha_0.1_res_num_5_opt_Adam_fold_0.hdf5
Epoch 44/1000
34/34 - 14s - loss: 1.2090 - accuracy: 0.7794 - val_loss: 1.3288 - val_accuracy: 0.7656

Epoch 00044: val_loss did not improve from 1.26776
Epoch 45/1000
34/34 - 14s - loss: 1.2746 - accuracy: 0.7601 - val_loss: 1.4515 - val_accuracy: 0.7109

Epoch 00045: val_loss did not improve from 1.26776
Epoch 46/1000
34/34 - 14s - loss: 1.1879 - accuracy: 0.7840 - val_loss: 1.4173 - val_accuracy: 0.7305

Epoch 00046: val_loss did not improve from 1.26776
Epoch 47/1000
34/34 - 14s - loss: 1.2757 - accuracy: 0.7560 - val_loss: 1.3689 - val_accuracy: 0.7461

Epoch 00047: val_loss did not improve from 1.26776

Epoch 00047: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.
Epoch 48/1000
34/34 - 14s - loss: 1.1675 - accuracy: 0.7854 - val_loss: 1.2542 - val_accuracy: 0.7695

Epoch 00048: val_loss improved from 1.26776 to 1.25420, saving model to ./save/nonBN_CNN_RNN_Resnet_5_use_mp_alpha_0.1_res_num_5_opt_Adam_fold_0.hdf5
Epoch 49/1000
34/34 - 14s - loss: 1.0894 - accuracy: 0.8006 - val_loss: 1.2697 - val_accuracy: 0.7578

Epoch 00049: val_loss did not improve from 1.25420
Epoch 50/1000
34/34 - 14s - loss: 1.0903 - accuracy: 0.8010 - val_loss: 1.2401 - val_accuracy: 0.7891

Epoch 00050: val_loss improved from 1.25420 to 1.24011, saving model to ./save/nonBN_CNN_RNN_Resnet_5_use_mp_alpha_0.1_res_num_5_opt_Adam_fold_0.hdf5
Epoch 51/1000
34/34 - 14s - loss: 1.0210 - accuracy: 0.8231 - val_loss: 1.2577 - val_accuracy: 0.7734

Epoch 00051: val_loss did not improve from 1.24011
Epoch 52/1000
34/34 - 14s - loss: 1.0398 - accuracy: 0.8130 - val_loss: 1.2407 - val_accuracy: 0.7773

Epoch 00052: val_loss did not improve from 1.24011
Epoch 53/1000
34/34 - 14s - loss: 1.0008 - accuracy: 0.8226 - val_loss: 1.1886 - val_accuracy: 0.7773

Epoch 00053: val_loss improved from 1.24011 to 1.18858, saving model to ./save/nonBN_CNN_RNN_Resnet_5_use_mp_alpha_0.1_res_num_5_opt_Adam_fold_0.hdf5
Epoch 54/1000
34/34 - 14s - loss: 0.9782 - accuracy: 0.8369 - val_loss: 1.2648 - val_accuracy: 0.7734

Epoch 00054: val_loss did not improve from 1.18858
Epoch 55/1000
34/34 - 14s - loss: 1.0594 - accuracy: 0.7918 - val_loss: 1.2056 - val_accuracy: 0.7578

Epoch 00055: val_loss did not improve from 1.18858
Epoch 56/1000
34/34 - 14s - loss: 1.0483 - accuracy: 0.7969 - val_loss: 1.2326 - val_accuracy: 0.7773

Epoch 00056: val_loss did not improve from 1.18858
Epoch 57/1000
34/34 - 14s - loss: 0.9911 - accuracy: 0.8199 - val_loss: 1.1628 - val_accuracy: 0.7891

Epoch 00057: val_loss improved from 1.18858 to 1.16284, saving model to ./save/nonBN_CNN_RNN_Resnet_5_use_mp_alpha_0.1_res_num_5_opt_Adam_fold_0.hdf5
Epoch 58/1000
34/34 - 14s - loss: 0.9833 - accuracy: 0.8203 - val_loss: 1.1376 - val_accuracy: 0.8047

Epoch 00058: val_loss improved from 1.16284 to 1.13764, saving model to ./save/nonBN_CNN_RNN_Resnet_5_use_mp_alpha_0.1_res_num_5_opt_Adam_fold_0.hdf5
Epoch 59/1000
34/34 - 14s - loss: 0.9998 - accuracy: 0.8120 - val_loss: 1.1880 - val_accuracy: 0.7734

Epoch 00059: val_loss did not improve from 1.13764
Epoch 60/1000
34/34 - 14s - loss: 1.0036 - accuracy: 0.8226 - val_loss: 1.1390 - val_accuracy: 0.7773

Epoch 00060: val_loss did not improve from 1.13764
Epoch 61/1000
34/34 - 14s - loss: 1.0750 - accuracy: 0.7946 - val_loss: 1.2222 - val_accuracy: 0.7656

Epoch 00061: val_loss did not improve from 1.13764
Epoch 62/1000
34/34 - 14s - loss: 0.9353 - accuracy: 0.8281 - val_loss: 1.2233 - val_accuracy: 0.7812

Epoch 00062: val_loss did not improve from 1.13764

Epoch 00062: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.
Epoch 63/1000
34/34 - 14s - loss: 0.8987 - accuracy: 0.8396 - val_loss: 1.1783 - val_accuracy: 0.7852

Epoch 00063: val_loss did not improve from 1.13764
Epoch 64/1000
34/34 - 14s - loss: 0.8780 - accuracy: 0.8451 - val_loss: 1.1453 - val_accuracy: 0.7969

Epoch 00064: val_loss did not improve from 1.13764
Epoch 65/1000
34/34 - 14s - loss: 0.8435 - accuracy: 0.8580 - val_loss: 1.1372 - val_accuracy: 0.7891

Epoch 00065: val_loss improved from 1.13764 to 1.13721, saving model to ./save/nonBN_CNN_RNN_Resnet_5_use_mp_alpha_0.1_res_num_5_opt_Adam_fold_0.hdf5
Epoch 66/1000
34/34 - 14s - loss: 0.8971 - accuracy: 0.8415 - val_loss: 1.1662 - val_accuracy: 0.7734

Epoch 00066: val_loss did not improve from 1.13721
Epoch 67/1000
34/34 - 14s - loss: 0.9040 - accuracy: 0.8369 - val_loss: 1.1280 - val_accuracy: 0.8008

Epoch 00067: val_loss improved from 1.13721 to 1.12798, saving model to ./save/nonBN_CNN_RNN_Resnet_5_use_mp_alpha_0.1_res_num_5_opt_Adam_fold_0.hdf5
Epoch 68/1000
34/34 - 14s - loss: 0.8968 - accuracy: 0.8359 - val_loss: 1.1640 - val_accuracy: 0.7852

Epoch 00068: val_loss did not improve from 1.12798
Epoch 69/1000
34/34 - 14s - loss: 0.8316 - accuracy: 0.8552 - val_loss: 1.1519 - val_accuracy: 0.7930

Epoch 00069: val_loss did not improve from 1.12798
Epoch 70/1000
34/34 - 14s - loss: 0.8423 - accuracy: 0.8543 - val_loss: 1.1439 - val_accuracy: 0.7812

Epoch 00070: val_loss did not improve from 1.12798
Epoch 71/1000
34/34 - 14s - loss: 0.8545 - accuracy: 0.8433 - val_loss: 1.1203 - val_accuracy: 0.7891

Epoch 00071: val_loss improved from 1.12798 to 1.12027, saving model to ./save/nonBN_CNN_RNN_Resnet_5_use_mp_alpha_0.1_res_num_5_opt_Adam_fold_0.hdf5
Epoch 72/1000
34/34 - 14s - loss: 0.9312 - accuracy: 0.8217 - val_loss: 1.1364 - val_accuracy: 0.7891

Epoch 00072: val_loss did not improve from 1.12027
Epoch 73/1000
34/34 - 14s - loss: 0.8938 - accuracy: 0.8387 - val_loss: 1.1086 - val_accuracy: 0.7969

Epoch 00073: val_loss improved from 1.12027 to 1.10860, saving model to ./save/nonBN_CNN_RNN_Resnet_5_use_mp_alpha_0.1_res_num_5_opt_Adam_fold_0.hdf5
Epoch 74/1000
34/34 - 14s - loss: 0.8632 - accuracy: 0.8497 - val_loss: 1.1449 - val_accuracy: 0.7930

Epoch 00074: val_loss did not improve from 1.10860
Epoch 75/1000
34/34 - 14s - loss: 0.8645 - accuracy: 0.8534 - val_loss: 1.1353 - val_accuracy: 0.7734

Epoch 00075: val_loss did not improve from 1.10860
Epoch 76/1000
34/34 - 14s - loss: 0.8039 - accuracy: 0.8635 - val_loss: 1.0876 - val_accuracy: 0.7930

Epoch 00076: val_loss improved from 1.10860 to 1.08755, saving model to ./save/nonBN_CNN_RNN_Resnet_5_use_mp_alpha_0.1_res_num_5_opt_Adam_fold_0.hdf5
Epoch 77/1000
34/34 - 14s - loss: 0.8449 - accuracy: 0.8428 - val_loss: 1.1114 - val_accuracy: 0.7812

Epoch 00077: val_loss did not improve from 1.08755
Epoch 78/1000
34/34 - 14s - loss: 0.7894 - accuracy: 0.8644 - val_loss: 1.1022 - val_accuracy: 0.8008

Epoch 00078: val_loss did not improve from 1.08755
Epoch 79/1000
34/34 - 14s - loss: 0.7923 - accuracy: 0.8699 - val_loss: 1.0386 - val_accuracy: 0.8008

Epoch 00079: val_loss improved from 1.08755 to 1.03864, saving model to ./save/nonBN_CNN_RNN_Resnet_5_use_mp_alpha_0.1_res_num_5_opt_Adam_fold_0.hdf5
Epoch 80/1000
34/34 - 14s - loss: 0.7960 - accuracy: 0.8644 - val_loss: 1.1077 - val_accuracy: 0.7891

Epoch 00080: val_loss did not improve from 1.03864
Epoch 81/1000
34/34 - 14s - loss: 0.8119 - accuracy: 0.8552 - val_loss: 1.1356 - val_accuracy: 0.7969

Epoch 00081: val_loss did not improve from 1.03864
Epoch 82/1000
34/34 - 14s - loss: 0.7637 - accuracy: 0.8791 - val_loss: 1.0874 - val_accuracy: 0.8008

Epoch 00082: val_loss did not improve from 1.03864
Epoch 83/1000
34/34 - 14s - loss: 0.8055 - accuracy: 0.8534 - val_loss: 1.0768 - val_accuracy: 0.8047

Epoch 00083: val_loss did not improve from 1.03864

Epoch 00083: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.
Epoch 84/1000
34/34 - 14s - loss: 0.7897 - accuracy: 0.8631 - val_loss: 1.0692 - val_accuracy: 0.7734

Epoch 00084: val_loss did not improve from 1.03864
Epoch 85/1000
34/34 - 14s - loss: 0.7556 - accuracy: 0.8741 - val_loss: 1.1150 - val_accuracy: 0.7773

Epoch 00085: val_loss did not improve from 1.03864
Epoch 86/1000
34/34 - 14s - loss: 0.8069 - accuracy: 0.8562 - val_loss: 1.0468 - val_accuracy: 0.7812

Epoch 00086: val_loss did not improve from 1.03864
Epoch 87/1000
34/34 - 14s - loss: 0.7770 - accuracy: 0.8653 - val_loss: 1.1098 - val_accuracy: 0.7969

Epoch 00087: val_loss did not improve from 1.03864

Epoch 00087: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.
Epoch 88/1000
34/34 - 14s - loss: 0.7123 - accuracy: 0.8879 - val_loss: 1.0457 - val_accuracy: 0.8164

Epoch 00088: val_loss did not improve from 1.03864
Epoch 89/1000
34/34 - 14s - loss: 0.7266 - accuracy: 0.8851 - val_loss: 1.0313 - val_accuracy: 0.8086

Epoch 00089: val_loss improved from 1.03864 to 1.03131, saving model to ./save/nonBN_CNN_RNN_Resnet_5_use_mp_alpha_0.1_res_num_5_opt_Adam_fold_0.hdf5
Epoch 90/1000
34/34 - 14s - loss: 0.6576 - accuracy: 0.9108 - val_loss: 1.0872 - val_accuracy: 0.8086

Epoch 00090: val_loss did not improve from 1.03131
Epoch 91/1000
34/34 - 14s - loss: 0.7411 - accuracy: 0.8801 - val_loss: 1.0303 - val_accuracy: 0.8242

Epoch 00091: val_loss improved from 1.03131 to 1.03027, saving model to ./save/nonBN_CNN_RNN_Resnet_5_use_mp_alpha_0.1_res_num_5_opt_Adam_fold_0.hdf5
Epoch 92/1000
34/34 - 14s - loss: 0.7162 - accuracy: 0.8842 - val_loss: 1.0792 - val_accuracy: 0.7969

Epoch 00092: val_loss did not improve from 1.03027
Epoch 93/1000
34/34 - 14s - loss: 0.7413 - accuracy: 0.8805 - val_loss: 1.0266 - val_accuracy: 0.8047

Epoch 00093: val_loss improved from 1.03027 to 1.02661, saving model to ./save/nonBN_CNN_RNN_Resnet_5_use_mp_alpha_0.1_res_num_5_opt_Adam_fold_0.hdf5
Epoch 94/1000
34/34 - 14s - loss: 0.7295 - accuracy: 0.8833 - val_loss: 1.0876 - val_accuracy: 0.7930

Epoch 00094: val_loss did not improve from 1.02661
Epoch 95/1000
34/34 - 14s - loss: 0.6862 - accuracy: 0.8971 - val_loss: 1.0613 - val_accuracy: 0.8086

Epoch 00095: val_loss did not improve from 1.02661
Epoch 96/1000
34/34 - 14s - loss: 0.7066 - accuracy: 0.8897 - val_loss: 1.0446 - val_accuracy: 0.8047

Epoch 00096: val_loss did not improve from 1.02661
Epoch 97/1000
34/34 - 14s - loss: 0.6786 - accuracy: 0.9003 - val_loss: 1.0481 - val_accuracy: 0.8086

Epoch 00097: val_loss did not improve from 1.02661

Epoch 00097: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.
Epoch 98/1000
34/34 - 14s - loss: 0.6852 - accuracy: 0.9017 - val_loss: 1.0176 - val_accuracy: 0.8086

Epoch 00098: val_loss improved from 1.02661 to 1.01756, saving model to ./save/nonBN_CNN_RNN_Resnet_5_use_mp_alpha_0.1_res_num_5_opt_Adam_fold_0.hdf5
Epoch 99/1000
34/34 - 14s - loss: 0.7112 - accuracy: 0.8906 - val_loss: 1.0660 - val_accuracy: 0.7969

Epoch 00099: val_loss did not improve from 1.01756
Epoch 100/1000
34/34 - 14s - loss: 0.6830 - accuracy: 0.8989 - val_loss: 1.0338 - val_accuracy: 0.8047

Epoch 00100: val_loss did not improve from 1.01756
Epoch 101/1000
34/34 - 14s - loss: 0.7129 - accuracy: 0.8865 - val_loss: 1.0752 - val_accuracy: 0.8008

Epoch 00101: val_loss did not improve from 1.01756
Epoch 102/1000
34/34 - 14s - loss: 0.6865 - accuracy: 0.8957 - val_loss: 1.0807 - val_accuracy: 0.7891

Epoch 00102: val_loss did not improve from 1.01756

Epoch 00102: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.
Epoch 103/1000
34/34 - 15s - loss: 0.6541 - accuracy: 0.9099 - val_loss: 1.0414 - val_accuracy: 0.8047

Epoch 00103: val_loss did not improve from 1.01756
Epoch 104/1000
34/34 - 14s - loss: 0.6727 - accuracy: 0.9067 - val_loss: 1.0326 - val_accuracy: 0.8203

Epoch 00104: val_loss did not improve from 1.01756
Epoch 105/1000
34/34 - 14s - loss: 0.7012 - accuracy: 0.8892 - val_loss: 1.0132 - val_accuracy: 0.8125

Epoch 00105: val_loss improved from 1.01756 to 1.01322, saving model to ./save/nonBN_CNN_RNN_Resnet_5_use_mp_alpha_0.1_res_num_5_opt_Adam_fold_0.hdf5
Epoch 106/1000
34/34 - 14s - loss: 0.7130 - accuracy: 0.8856 - val_loss: 1.0142 - val_accuracy: 0.8125

Epoch 00106: val_loss did not improve from 1.01322
Epoch 107/1000
34/34 - 14s - loss: 0.6745 - accuracy: 0.8998 - val_loss: 1.0570 - val_accuracy: 0.8008

Epoch 00107: val_loss did not improve from 1.01322
Epoch 108/1000
34/34 - 14s - loss: 0.6757 - accuracy: 0.9021 - val_loss: 1.0690 - val_accuracy: 0.7969

Epoch 00108: val_loss did not improve from 1.01322
Epoch 109/1000
34/34 - 14s - loss: 0.7323 - accuracy: 0.8782 - val_loss: 1.0404 - val_accuracy: 0.7969

Epoch 00109: val_loss did not improve from 1.01322

Epoch 00109: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.
Epoch 110/1000
34/34 - 14s - loss: 0.6606 - accuracy: 0.9081 - val_loss: 1.0798 - val_accuracy: 0.7969

Epoch 00110: val_loss did not improve from 1.01322
Epoch 111/1000
34/34 - 14s - loss: 0.6917 - accuracy: 0.8957 - val_loss: 1.0569 - val_accuracy: 0.7969

Epoch 00111: val_loss did not improve from 1.01322
Epoch 112/1000
34/34 - 14s - loss: 0.6686 - accuracy: 0.9049 - val_loss: 1.0602 - val_accuracy: 0.8008

Epoch 00112: val_loss did not improve from 1.01322
Epoch 113/1000
34/34 - 14s - loss: 0.6660 - accuracy: 0.9044 - val_loss: 1.0724 - val_accuracy: 0.7930

Epoch 00113: val_loss did not improve from 1.01322

Epoch 00113: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.
Epoch 114/1000
34/34 - 14s - loss: 0.6800 - accuracy: 0.8980 - val_loss: 1.0634 - val_accuracy: 0.7969

Epoch 00114: val_loss did not improve from 1.01322
Epoch 115/1000
34/34 - 14s - loss: 0.6455 - accuracy: 0.9085 - val_loss: 1.0342 - val_accuracy: 0.8086

Epoch 00115: val_loss did not improve from 1.01322
Epoch 116/1000
34/34 - 14s - loss: 0.7588 - accuracy: 0.8667 - val_loss: 1.0379 - val_accuracy: 0.8008

Epoch 00116: val_loss did not improve from 1.01322
Epoch 117/1000
34/34 - 14s - loss: 0.7150 - accuracy: 0.8874 - val_loss: 1.0679 - val_accuracy: 0.7930

Epoch 00117: val_loss did not improve from 1.01322

Epoch 00117: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.
Epoch 118/1000
34/34 - 14s - loss: 0.6722 - accuracy: 0.9035 - val_loss: 1.0248 - val_accuracy: 0.8008

Epoch 00118: val_loss did not improve from 1.01322
Epoch 119/1000
34/34 - 14s - loss: 0.7234 - accuracy: 0.8869 - val_loss: 1.0435 - val_accuracy: 0.8008

Epoch 00119: val_loss did not improve from 1.01322
Epoch 120/1000
34/34 - 14s - loss: 0.6766 - accuracy: 0.8989 - val_loss: 1.0452 - val_accuracy: 0.7969

Epoch 00120: val_loss did not improve from 1.01322
Epoch 121/1000
34/34 - 14s - loss: 0.7219 - accuracy: 0.8902 - val_loss: 1.0685 - val_accuracy: 0.7930

Epoch 00121: val_loss did not improve from 1.01322

Epoch 00121: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.
Epoch 122/1000
34/34 - 14s - loss: 0.6759 - accuracy: 0.9017 - val_loss: 1.0634 - val_accuracy: 0.7930

Epoch 00122: val_loss did not improve from 1.01322
Epoch 123/1000
34/34 - 14s - loss: 0.7002 - accuracy: 0.8938 - val_loss: 1.0626 - val_accuracy: 0.7930

Epoch 00123: val_loss did not improve from 1.01322
Epoch 124/1000
34/34 - 14s - loss: 0.7037 - accuracy: 0.8888 - val_loss: 1.0681 - val_accuracy: 0.7930

Epoch 00124: val_loss did not improve from 1.01322
Epoch 125/1000
34/34 - 14s - loss: 0.6632 - accuracy: 0.9076 - val_loss: 1.0534 - val_accuracy: 0.8008

Epoch 00125: val_loss did not improve from 1.01322

Epoch 00125: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.
Epoch 126/1000
34/34 - 14s - loss: 0.6684 - accuracy: 0.9081 - val_loss: 1.0646 - val_accuracy: 0.7930

Epoch 00126: val_loss did not improve from 1.01322
Epoch 127/1000
34/34 - 14s - loss: 0.6456 - accuracy: 0.9127 - val_loss: 1.0740 - val_accuracy: 0.7969

Epoch 00127: val_loss did not improve from 1.01322
Epoch 128/1000
34/34 - 14s - loss: 0.6692 - accuracy: 0.9012 - val_loss: 1.0389 - val_accuracy: 0.8047

Epoch 00128: val_loss did not improve from 1.01322
Epoch 129/1000
34/34 - 14s - loss: 0.6824 - accuracy: 0.8961 - val_loss: 1.0622 - val_accuracy: 0.7969

Epoch 00129: val_loss did not improve from 1.01322

Epoch 00129: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.
Epoch 130/1000
34/34 - 14s - loss: 0.6621 - accuracy: 0.9049 - val_loss: 1.0454 - val_accuracy: 0.8047

Epoch 00130: val_loss did not improve from 1.01322
Epoch 131/1000
34/34 - 14s - loss: 0.6694 - accuracy: 0.9003 - val_loss: 1.0617 - val_accuracy: 0.8008

Epoch 00131: val_loss did not improve from 1.01322
Epoch 132/1000
34/34 - 14s - loss: 0.6816 - accuracy: 0.8948 - val_loss: 1.0429 - val_accuracy: 0.8125

Epoch 00132: val_loss did not improve from 1.01322
Epoch 133/1000
34/34 - 14s - loss: 0.6926 - accuracy: 0.8980 - val_loss: 1.0588 - val_accuracy: 0.8008

Epoch 00133: val_loss did not improve from 1.01322

Epoch 00133: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.
Epoch 134/1000
34/34 - 14s - loss: 0.6756 - accuracy: 0.9003 - val_loss: 1.0637 - val_accuracy: 0.8008

Epoch 00134: val_loss did not improve from 1.01322
Epoch 135/1000
34/34 - 14s - loss: 0.7029 - accuracy: 0.8934 - val_loss: 1.0089 - val_accuracy: 0.8086

Epoch 00135: val_loss improved from 1.01322 to 1.00889, saving model to ./save/nonBN_CNN_RNN_Resnet_5_use_mp_alpha_0.1_res_num_5_opt_Adam_fold_0.hdf5
Epoch 136/1000
34/34 - 14s - loss: 0.7005 - accuracy: 0.8938 - val_loss: 1.0523 - val_accuracy: 0.8047

Epoch 00136: val_loss did not improve from 1.00889
Epoch 137/1000
34/34 - 14s - loss: 0.7117 - accuracy: 0.8828 - val_loss: 1.0678 - val_accuracy: 0.7969

Epoch 00137: val_loss did not improve from 1.00889
Epoch 138/1000
34/34 - 14s - loss: 0.7108 - accuracy: 0.8883 - val_loss: 1.0747 - val_accuracy: 0.7969

Epoch 00138: val_loss did not improve from 1.00889
Epoch 139/1000
34/34 - 14s - loss: 0.6983 - accuracy: 0.8874 - val_loss: 1.0285 - val_accuracy: 0.8203

Epoch 00139: val_loss did not improve from 1.00889

Epoch 00139: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.
Epoch 140/1000
34/34 - 14s - loss: 0.6639 - accuracy: 0.9067 - val_loss: 1.0634 - val_accuracy: 0.8008

Epoch 00140: val_loss did not improve from 1.00889
Epoch 141/1000
34/34 - 14s - loss: 0.6869 - accuracy: 0.8948 - val_loss: 1.0181 - val_accuracy: 0.8047

Epoch 00141: val_loss did not improve from 1.00889
Epoch 142/1000
34/34 - 14s - loss: 0.7166 - accuracy: 0.8837 - val_loss: 1.0725 - val_accuracy: 0.7930

Epoch 00142: val_loss did not improve from 1.00889
Epoch 143/1000
34/34 - 14s - loss: 0.6696 - accuracy: 0.9017 - val_loss: 1.0531 - val_accuracy: 0.7969

Epoch 00143: val_loss did not improve from 1.00889

Epoch 00143: ReduceLROnPlateau reducing learning rate to 3.051757957450718e-08.
Epoch 144/1000
34/34 - 15s - loss: 0.7052 - accuracy: 0.8883 - val_loss: 1.0529 - val_accuracy: 0.8008

Epoch 00144: val_loss did not improve from 1.00889
Epoch 145/1000
34/34 - 14s - loss: 0.6598 - accuracy: 0.9081 - val_loss: 1.0665 - val_accuracy: 0.7969

Epoch 00145: val_loss did not improve from 1.00889
Epoch 146/1000
34/34 - 14s - loss: 0.6744 - accuracy: 0.9049 - val_loss: 1.0504 - val_accuracy: 0.8008

Epoch 00146: val_loss did not improve from 1.00889
Epoch 147/1000
34/34 - 14s - loss: 0.6927 - accuracy: 0.8961 - val_loss: 1.0527 - val_accuracy: 0.8008

Epoch 00147: val_loss did not improve from 1.00889

Epoch 00147: ReduceLROnPlateau reducing learning rate to 1.525878978725359e-08.
Epoch 148/1000
34/34 - 14s - loss: 0.6898 - accuracy: 0.8961 - val_loss: 1.0485 - val_accuracy: 0.8008

Epoch 00148: val_loss did not improve from 1.00889
Epoch 149/1000
34/34 - 14s - loss: 0.6898 - accuracy: 0.8961 - val_loss: 1.0801 - val_accuracy: 0.7930

Epoch 00149: val_loss did not improve from 1.00889
Epoch 150/1000
34/34 - 14s - loss: 0.6897 - accuracy: 0.8994 - val_loss: 1.0491 - val_accuracy: 0.8008

Epoch 00150: val_loss did not improve from 1.00889
Epoch 151/1000
34/34 - 14s - loss: 0.6753 - accuracy: 0.9044 - val_loss: 1.0679 - val_accuracy: 0.8008

Epoch 00151: val_loss did not improve from 1.00889

Epoch 00151: ReduceLROnPlateau reducing learning rate to 7.629394893626795e-09.
Epoch 152/1000
34/34 - 14s - loss: 0.6863 - accuracy: 0.9007 - val_loss: 1.0339 - val_accuracy: 0.8125

Epoch 00152: val_loss did not improve from 1.00889
Epoch 153/1000
34/34 - 14s - loss: 0.6638 - accuracy: 0.9062 - val_loss: 0.9970 - val_accuracy: 0.8047

Epoch 00153: val_loss improved from 1.00889 to 0.99701, saving model to ./save/nonBN_CNN_RNN_Resnet_5_use_mp_alpha_0.1_res_num_5_opt_Adam_fold_0.hdf5
Epoch 154/1000
34/34 - 14s - loss: 0.6824 - accuracy: 0.8938 - val_loss: 1.0168 - val_accuracy: 0.8164

Epoch 00154: val_loss did not improve from 0.99701
Epoch 155/1000
34/34 - 14s - loss: 0.7311 - accuracy: 0.8814 - val_loss: 1.0642 - val_accuracy: 0.8008

Epoch 00155: val_loss did not improve from 0.99701
Epoch 156/1000
34/34 - 14s - loss: 0.6440 - accuracy: 0.9072 - val_loss: 1.0714 - val_accuracy: 0.7969

Epoch 00156: val_loss did not improve from 0.99701
Epoch 157/1000
34/34 - 14s - loss: 0.6634 - accuracy: 0.9044 - val_loss: 1.0631 - val_accuracy: 0.8008

Epoch 00157: val_loss did not improve from 0.99701

Epoch 00157: ReduceLROnPlateau reducing learning rate to 3.814697446813398e-09.
Epoch 158/1000
34/34 - 14s - loss: 0.6984 - accuracy: 0.8980 - val_loss: 1.0614 - val_accuracy: 0.8008

Epoch 00158: val_loss did not improve from 0.99701
Epoch 159/1000
34/34 - 14s - loss: 0.6866 - accuracy: 0.8984 - val_loss: 1.0484 - val_accuracy: 0.8086

Epoch 00159: val_loss did not improve from 0.99701
Epoch 160/1000
34/34 - 14s - loss: 0.6937 - accuracy: 0.8906 - val_loss: 1.0554 - val_accuracy: 0.7969

Epoch 00160: val_loss did not improve from 0.99701
Epoch 161/1000
34/34 - 14s - loss: 0.6591 - accuracy: 0.9081 - val_loss: 1.0653 - val_accuracy: 0.8008

Epoch 00161: val_loss did not improve from 0.99701

Epoch 00161: ReduceLROnPlateau reducing learning rate to 1.907348723406699e-09.
Epoch 162/1000
34/34 - 14s - loss: 0.6854 - accuracy: 0.8998 - val_loss: 1.0612 - val_accuracy: 0.8008

Epoch 00162: val_loss did not improve from 0.99701
Epoch 163/1000
34/34 - 14s - loss: 0.6811 - accuracy: 0.9017 - val_loss: 1.0826 - val_accuracy: 0.7930

Epoch 00163: val_loss did not improve from 0.99701
Epoch 164/1000
34/34 - 14s - loss: 0.6647 - accuracy: 0.9131 - val_loss: 1.0495 - val_accuracy: 0.8047

Epoch 00164: val_loss did not improve from 0.99701
Epoch 165/1000
34/34 - 14s - loss: 0.6786 - accuracy: 0.8897 - val_loss: 1.0692 - val_accuracy: 0.8008

Epoch 00165: val_loss did not improve from 0.99701

Epoch 00165: ReduceLROnPlateau reducing learning rate to 9.536743617033494e-10.
Epoch 166/1000
34/34 - 14s - loss: 0.6496 - accuracy: 0.9081 - val_loss: 1.0676 - val_accuracy: 0.8008

Epoch 00166: val_loss did not improve from 0.99701
Epoch 167/1000
34/34 - 14s - loss: 0.6895 - accuracy: 0.8906 - val_loss: 1.0613 - val_accuracy: 0.8047

Epoch 00167: val_loss did not improve from 0.99701
Epoch 168/1000
34/34 - 14s - loss: 0.6625 - accuracy: 0.9062 - val_loss: 1.0313 - val_accuracy: 0.8164

Epoch 00168: val_loss did not improve from 0.99701
Epoch 169/1000
34/34 - 14s - loss: 0.7055 - accuracy: 0.8860 - val_loss: 1.0577 - val_accuracy: 0.8008

Epoch 00169: val_loss did not improve from 0.99701

Epoch 00169: ReduceLROnPlateau reducing learning rate to 4.768371808516747e-10.
Epoch 170/1000
34/34 - 14s - loss: 0.6822 - accuracy: 0.9021 - val_loss: 1.0040 - val_accuracy: 0.8086

Epoch 00170: val_loss did not improve from 0.99701
Epoch 171/1000
34/34 - 14s - loss: 0.6711 - accuracy: 0.8980 - val_loss: 1.0343 - val_accuracy: 0.8086

Epoch 00171: val_loss did not improve from 0.99701
Epoch 172/1000
34/34 - 14s - loss: 0.6514 - accuracy: 0.9099 - val_loss: 1.0625 - val_accuracy: 0.8008

Epoch 00172: val_loss did not improve from 0.99701
Epoch 173/1000
34/34 - 14s - loss: 0.6712 - accuracy: 0.9081 - val_loss: 1.0016 - val_accuracy: 0.8164

Epoch 00173: val_loss did not improve from 0.99701

Epoch 00173: ReduceLROnPlateau reducing learning rate to 2.3841859042583735e-10.
Epoch 174/1000
34/34 - 14s - loss: 0.6820 - accuracy: 0.8961 - val_loss: 1.0634 - val_accuracy: 0.8008

Epoch 00174: val_loss did not improve from 0.99701
Epoch 175/1000
34/34 - 14s - loss: 0.6536 - accuracy: 0.9113 - val_loss: 1.0737 - val_accuracy: 0.7930

Epoch 00175: val_loss did not improve from 0.99701
Epoch 176/1000
34/34 - 14s - loss: 0.6938 - accuracy: 0.8892 - val_loss: 1.0485 - val_accuracy: 0.8008

Epoch 00176: val_loss did not improve from 0.99701
Epoch 177/1000
34/34 - 14s - loss: 0.6897 - accuracy: 0.8943 - val_loss: 1.0617 - val_accuracy: 0.8008

Epoch 00177: val_loss did not improve from 0.99701

Epoch 00177: ReduceLROnPlateau reducing learning rate to 1.1920929521291868e-10.
Epoch 178/1000
34/34 - 14s - loss: 0.6796 - accuracy: 0.8994 - val_loss: 1.0457 - val_accuracy: 0.8125

Epoch 00178: val_loss did not improve from 0.99701
Epoch 179/1000
34/34 - 14s - loss: 0.6526 - accuracy: 0.9099 - val_loss: 1.0338 - val_accuracy: 0.8047

Epoch 00179: val_loss did not improve from 0.99701
Epoch 180/1000
34/34 - 14s - loss: 0.6694 - accuracy: 0.9053 - val_loss: 1.0605 - val_accuracy: 0.8008

Epoch 00180: val_loss did not improve from 0.99701
Epoch 181/1000
34/34 - 14s - loss: 0.6611 - accuracy: 0.9044 - val_loss: 1.0436 - val_accuracy: 0.8008

Epoch 00181: val_loss did not improve from 0.99701

Epoch 00181: ReduceLROnPlateau reducing learning rate to 5.960464760645934e-11.
Epoch 182/1000
34/34 - 14s - loss: 0.6712 - accuracy: 0.9017 - val_loss: 1.0241 - val_accuracy: 0.8047

Epoch 00182: val_loss did not improve from 0.99701
Epoch 183/1000
34/34 - 14s - loss: 0.6370 - accuracy: 0.9141 - val_loss: 1.0624 - val_accuracy: 0.8047

Epoch 00183: val_loss did not improve from 0.99701
Epoch 00183: early stopping
>> join - Process-1 at Tue Jul 27 14:31:16 2021
>> Process-1 spend 0h 46m 15.1s

>> start - Process-2 at Tue Jul 27 14:31:20 2021
Epoch 1/1000
